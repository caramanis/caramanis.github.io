<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Μηχανική Μάθηση και Τεχνητή Νοημοσύνη &middot; Constantine Caramanis
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body>

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h2>
        Constantine Caramanis
      </h2>
      <p class="lead"></p>
    </div>

    <nav class="sidebar-nav">


      

      <a class="sidebar-nav-item" href="/">Home</a>
      <a class="sidebar-nav-item" href="/teaching/">Teaching</a>
      <a class="sidebar-nav-item" href="/publications/">Publications</a>
      <a class="sidebar-nav-item" href="/researchgroup/">Research Group</a>
      <a class="sidebar-nav-item" href="/researchprojects/">Research Projects</a>
      <a class="sidebar-nav-item" href="https://scholar.google.com/citations?user=47YTUrEAAAAJ&hl=en&oi=ao" target="_blank">Google Scholar</a>
      <a class="sidebar-nav-item" href="https://www.youtube.com/channel/UCSv1_NZITsPl-abaCWtRrJg" target="_blank">YouTube</a>
      <a class="sidebar-nav-item" href="https://ml.utexas.edu/ifml" target="_blank">IFML</a>
      <a class="sidebar-nav-item" href="https://wncg.org" target="_blank">WNCG</a>
      <a class="sidebar-nav-item" href="https://archimedesai.gr/en/" target="_blank">Archimedes AI</a>




      <!--<span class="sidebar-nav-item">Jekyll Hyde, Currently v2.1.0</span>-->
    </nav>

    <p>&copy; 2025. All rights reserved.</p> 
  </div>
</div>


    <div class="content container">
      <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 20px;">
  <img src="/images/mlclass/logo_archimedes_arc.jpg" alt="Left Logo" style="height: 50px;" />
  <img src="/images/mlclass/for_site_logo_en.jpg" alt="Right Logo" style="height: 50px;" />
</div>

<h1 id="μηχανική-μάθηση-και-τεχνητή-νοημοσύνη">Μηχανική Μάθηση και Τεχνητή Νοημοσύνη</h1>

<hr />

<p><span style="font-size: 16px;">Καλωσορίσατε στο μάθημα τεχνητής νοημοσύνης και μηχανικής μάθησης. 
Αυτό το μάθημα δεν επιδιώκει να αναπτύξει μία ολοκληρωμένη βάση των ιδεών και των αλγορίθμων της μηχανικής μάθησης, αλλά μάλλον να χτίσει έναν βασικό πυρήνα των ιδεών, ο οποίος μπορεί να επεκταθεί εύκολα, αλλά και να χρησιμοποιηθεί άμεσα. Σκοπός μας είναι να προχωρήσουμε γρήγορα τόσο με τις βασικές ιδέες, όσο και με την υλοποίησή τους στην γλώσσα Python και στις βασικές της βιβλιοθήκες, ώστε να μπορείτε να τις εφαρμόσετε και μόνοι σας σε πρότζεκτ και προβλήματα που κεντρίζουν το δικό σας ενδιαφέρον.<br />
<br />
Θα βρείτε παρακάτω λινκς σε μια σειρά από διαλέξεων, οργανωμένα θεματικά σε “Modules”. Χρησιμοποιούμε διαφάνειες όταν πρωτοεισάγουμε και εξηγούμε μία καινούργια ιδέα. Στις επόμενες διαλέξεις, αναπτύσσουμε και υλοποιούμε αυτές τις ιδέες στην Python, για να βρούμε λύσεις σε προβλήματα της μηχανικής μάθησης, με πραγματικά και επίσης τεχνητά δεδομένα.<br />
<br />
Python και Colab: θα χρησιμοποιήσουμε την γλώσσα προγραμματισμού Python. Δεν καλύπτουμε τις αρχές της Python από το μηδέν. Παρόλα αυτά, στις διαλέξεις εξηγούμε τις βασικές εντολές, και δίνουμε πληροφορίες για τις βιβλιοθήκες που χρησιμοποιούμε. Επίσης σε διάφορα σημείεα του κώδικα, σας προτείνω κάποια λινκς που περιέχουν παραπάνω λεπτομέρειες για τις συγκεκριμένες εντολές ή βιβλιοθήκες, που μπορείτε να ακολουθήσετε ώστε να εμβαθύνετε τις γνώσεις σας. Όλος ο προγραμματισμός θα γίνει στο <strong>Colab</strong>. Το Colab είναι ένα δωρεάν, βασισμένο στο cloud εργαλείο από την Google, το οποίο επιτρέπει τη συγγραφή και την εκτέλεση κώδικα Python σε περιβάλλον Jupyter Notebook. Δουλεύει εξ ολοκλήρου στον browser, χωρίς να απαιτείται εγκατάσταση λογισμικού ή ρύθμιση περιβάλλοντος, οπότε η χρήση του μας εξασφαλίζει πως όλοι έχουμε πρόσβαση στο ίδιο υπολογιστικό περιβάλλον. <em>Θα χρειαστείτε όμως λογαριασμό</em> <strong>gmail</strong>.<br />
<br />
Πως μπορείτε να χρησιμοποιήσετε την ύλη του μαθήματος:  </span>
<br />
<br /></p>
<div style="font-size: 16px;">
1. Οι διαλέξεις είναι σχεδιασμένες να τις παρακολουθείσετε με την σειρά, μαζί με το υλικό, δηλαδή, τις διαφάνειες ή τα Colab Notebook.  
<br />
2. Εάν θέλετε να πάρετε μια γρήγορη συνολική ιδέα του τι καλύπτει το μάθημα, μπορείτε να παρακολουθήσετε μόνο τα μαθήματα με διαφάνειες. Τα μαθήματα όπου υλοποιούμε αλγορίθμους σε Python έχουν στον τίτλο την επισήμανση "(Python / Colab)".  
<br />
3. Εάν έχετε ήδη εμπειρία χρησιμοποιώντας την Python και έχετε κάποια επαφή με τις ιδέες και τους αλγορίθμους της μηχανικής μάθησης, μπορείτε απλά να πάτε κατευθείαν στα Colab Notebooks που σας ενδιαφέρουν.  
<br />
4. Αυτά τα μαθήματα αποτελούν έναν βασικό κορμό ή πυρήνα, και σκοπός είναι να επεκταθεί. Όταν είναι έτοιμα καινούργιες διαλέξεις, θα τις βρείτε εδώ.
</div>

<hr />

<h3 id="εδώ-θα-βρείτε-λινκς-για-την-πλήρη-ύλη-του-μαθήματος"><strong>Εδώ θα βρείτε λινκς για την πλήρη ύλη του μαθήματος</strong>:</h3>

<div style="font-size: 16px;">
* Βιντεοσκοπημένα μαθήματα
* Διαφάνειες
* Colab Notebooks (Python κώδικα)
</div>

<hr />

<p>`</p>
<h3 id="module-1-εισαγωγή-στο-μάθημα-και-στην-τεχνητή-νοημοσύνη">Module 1: Εισαγωγή στο Μάθημα και στην Τεχνητή Νοημοσύνη</h3>

<ul>
  <li>
    <p><strong>Lecture 1: <a href="https://youtu.be/KxUD5Rc149Y">Τι είναι η Τεχνητή Νοημοσύνη; Τι θα καλύψει αυτό το μάθημα;</a></strong><br />
<img src="/images/mlclass/L01.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Σε αυτήν την διάλεξη δίνουμε κάποια πρώτα παραδείγματα, και ύστερα περιγράφουμε συνοπτικά όλο το μάθημα, την δομή των διαλέξεων, και τις προαπαιτούμενες γνώσεις για να παρακολουθήσετε τα μαθήματα.</em></p>

    <p><a href="/pdfs/mlclass/L01.pdf">Διαφάνειες</a></p>
  </li>
  <li>
    <p><strong>Lecture 2: <a href="https://youtu.be/lvTMKTXzjwk">Ο John Snow, η Χολέρα, και η Μοντέρνα Τεχνητή Νοημοσύνη</a></strong><br />
<img src="/images/mlclass/L02.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Σε αυτήν την διάλεξη συνεχίζουμε την συζήτησή μας για την τεχνητή νοημοσύνη. Αρχίζουμε με ένα ιστορικό παράδειγμα, και ύστερα περνάμε σε παραδείγματα εφαρμογών της μοντέρνας μηχανικής μάθησης. Με αυτόν τον τρόπο εξηγούμε την ιδέα της ταξινόμησης και παλινδρόμησης στην μηχανική όραση και στην επεξεργασία φυσικής γλώσσας. Επίσης συζητάμε την γενετική τεχνητή νοημοσύνη και κάποιες εφαρμογές.</em></p>

    <p><a href="/pdfs/mlclass/L02.pdf">Διαφάνειες</a></p>
  </li>
</ul>

<p>`</p>
<h3 id="module-2-επιτηρούμενη-μάθηση-supervised-learning">Module 2: Επιτηρούμενη Μάθηση (Supervised Learning)</h3>

<ul>
  <li>
    <p><strong>Lecture 3: <a href="https://youtu.be/R-05LXetsFw">Επιτηρούμενη Μάθηση και Δέντρα Απόφασης</a></strong><br />
<img src="/images/mlclass/L03.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Σε αυτήν την διάλεξη συζητάμε την βασική ιδέα του αλγορίθμου, και των παραμέτρων. Βασικός μας στόχος είναι να περιγράψουμε το βασικό πρότυπο της επιτηρούμενης μάθησης – supervised learning. Θα εξηγήσουμε τι θα πεί “εκπαιδεύω αλγόριθμο”. Η επόμενη διάλεξη μπαίνει λεπτομερώς στην υλοποίηση (με κώδικα) της επιτηρούμενης μάθησης στην Python.</em></p>

    <p><a href="/pdfs/mlclass/L03.pdf">Διαφάνειες</a></p>
  </li>
  <li>
    <p><strong>Lecture 4: <a href="https://youtu.be/tiEXSzf1Jcs">Δέντρα Απόφασης με δεδομένα του διαβήτη 1/2 (Python / Colab)</a></strong><br />
<img src="/images/mlclass/L04.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Σε αυτήν την διάλεξη, υλοποιούμε τις βασικές ιδέες στην Python. Μεταφορτώνουμε ένα σετ δεδομένων σχετικά με τον διαβήτη. Χρησιμοποιούμε εντολές της Pandas, την Numpy και της Matplotlib για να επεξεργαστούμε, να οπτικοποιήσουμε και να καθαρίσουμε τα δεδομένα. Ύστερα, χρησιμοποιούμε εντολές από την βιβλιοθήκη Sklearn για να εκπαιδεύσουμε δέντρα απόφασης.</em></p>

    <p><a href="https://colab.research.google.com/drive/162hNnEDlmoAzcNFhEMQFmMXFQeVPHgHr?usp=drive_link">Colab Notebook</a></p>
  </li>
  <li>
    <p><strong>Lecture 5: <a href="https://youtu.be/0VJXJOOMrhQ">Δέντρα Απόφασης με δεδομένα του διαβήτη 2/2 (Python / Colab)</a></strong><br />
<img src="/images/mlclass/L05.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Σε αυτήν την διάλεξη υμπληρώνουμε τις ασκήσεις που είχαμε περιγράψει στην προηγούμενη διάλεξη.</em></p>

    <p><a href="https://colab.research.google.com/drive/162hNnEDlmoAzcNFhEMQFmMXFQeVPHgHr?usp=sharing">Colab Notebook</a></p>
  </li>
</ul>

<p>`</p>
<h3 id="module-3-υπερμοντελοποίηση-και-υπομοντελοποίηση-overfitting-and-underfitting">Module 3: Υπερμοντελοποίηση και Υπομοντελοποίηση (Overfitting and Underfitting)</h3>

<ul>
  <li>
    <p><strong>Lecture 6: <a href="https://youtu.be/hsNyHqZkKbg">Υπερμοντελοποίηση:  οι βασικές ιδέες</a></strong><br />
<img src="/images/mlclass/L06.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Σε αυτήν την διάλεξη αρχίζουμε την συζήτησή μας για την υπερμοντελοποίηση (overfitting). Η υπερμοντελοποίηση περιγράφει το φαινόμενο όπου ένας αλγόριθμος ταιριάζει πολύ καλά (έχει μεγάλη ακρίβεια) στα δεδομένα με τα οποία εκπαιδεύτικε, αλλά έχει πολύ χειρότερη επίδοση (ακρίβεια) σε δεδομένα που δεν περιέχονται στα δεδομένα εκπαίδευσης. Αυτό συμβαίνει, όπως είδαμε, με τα δεδομένα του διαβήτη όταν εκπαιδεύουμε βαθιά δέντρα απόφασης.</em></p>

    <p><a href="/pdfs/mlclass/L06.pdf">Διαφάνειες</a></p>
  </li>
  <li>
    <p><strong>Lecture 7: <a href="https://youtu.be/7xRt4mJ8vmU">Υπερμοντελοποίηση στην Python (Python / Colab)</a></strong><br />
<img src="/images/mlclass/L07.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Συνεχίζουμε την συζήτησή μας για την υπερμοντελοποίηση, τώρα παρατηρώντας αυτό το φαινόμενο στην πράξη. Κοιτάμε πάλι τα δεδομένα του διαβήτη. Δημιουργούμε ένα τεχνητό σετ δεδομένων, και πάλι με βαθιά δέντρα απόφασης, παρατηρούμε και εκεί το φαινόμενο της υπερμοντελοποίησης: τα βαθιά δέντρα απόφασης υπερμοντελοποιούν διότι προσπαθούν να μοντελοποιήσουν τον θόρυβο στα δεδομένα εκπαίδευσης.</em></p>
  </li>
  <li>
    <p><strong>Lecture 8: <a href="https://youtu.be/XmD9Zxs9JBE">Υπερμοντελοποίηση με το CIFAR-10 (Python / Colab)</a></strong><br />
<img src="/images/mlclass/L08.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Σε αυτήν την διάλεξη συνεχίζουμε την συζήτηση για την υπερμοντελοποίηση και τα δέντρα απόφασης, τώρα με ένα πρόβλημα ταξινόμησης στην Μηχανική Όραση (computer vision), με τα δεδομένα του CIFAR-10. Είναι αφορμή να μάθουμε πως αποθηκεύονται οι εικόνες στον υπολογιστή, και επίσης να δούμε ένα πρόβλημα σημαντικά μεγαλύτερο από αυτά που έχουμε δεί εώς τώρα.</em></p>
  </li>
  <li>
    <p><strong>Lecture 9: <a href="https://youtu.be/K4ChsxSLPq0">Υπερμοντελοποίηση και Υπομονετλοποίηση στην Παλινδρόμηση (Python / Colab)</a></strong><br />
<img src="/images/mlclass/L09.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Σε αυτήν την διάλεξη ξανασυνταντάμε τις βασικές ιδέες που έχουμε αναπτύξει στο μάθημα, αλλά με προβλήματα παλινδρόμησης (regression). Συγκεκριμένα, συζητάμε το βασικό πρότυπο της επιτηρούμενης μάθησης και εκπαίδευσης αλγορίθμων, και την υπερμοντελοποίηση (overfitting). Επίσης, εξηγούμε την ιδέα της υπομοντελοποίησης (underfitting).</em></p>

    <p><a href="https://colab.research.google.com/drive/1gVhD4oqLVCGFTkL1JO6JDt2VpuDIOfNQ?usp=drive_link">Colab Notebook</a></p>
  </li>
</ul>

<p>`</p>
<h3 id="module-4-νευρωνικά-δίκτυα-neural-networks">Module 4: Νευρωνικά Δίκτυα (Neural Networks)</h3>

<ul>
  <li>
    <p><strong>Lecture 10: <a href="https://youtu.be/yrDRb_nLoFc">Εισαγωγή στα Νευρωνικά Δίκτυα</a></strong><br />
<img src="/images/mlclass/L06.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Σε αυτήν την διάλεξη αρχίζουμε την συζήτησή μας για βαθιά νευρωνικά δίκτυα (deep neural networks). Εξηγούμε δύο από τα βασικά δομικά στοιχεία των νευρωνικών δικτύων: τα fully-connected γραμμικά επίπεδα (fully connected layers), και το softmax.</em></p>

    <p><a href="/pdfs/mlclass/L10.pdf">Διαφάνειες</a></p>
  </li>
  <li>
    <p><strong>Lecture 11: <a href="https://youtu.be/yrDRb_nLoFc">Νευρωνικά Δίκτυα: ReLU</a></strong><br />
<img src="/images/mlclass/L11.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Συνεχίζουμε την συζήτησή μας για νευρωνικά δίτκυα. Απαντάμε την ερώτηση που έθεσε η προηγούμενη διάλεξη: ‘αρκούν τα γραμμικά επίπεδα για να χτίσουμε μια πλούσια οικογένεια νευρωνικών δικτύων;’ Βλέπουμε με ένα απλό παράδειγμα και υπολογισμό, πως δεν μπορούμε να βασιστούμε μόνο σε γραμμικά επίπεδα: δύο (ή και παραπάνω) γραμμικά επίπεδα στην σειρά, ισοδυναμούν με μόνο ένα γραμμικό επίπεδο. Είναι απαραίτητα, λοιπόν, κάποια μη-γραμμικά επίπεδα: τα ReLU (ή κάτι παρόμοιο). Ύστερα, εξηγούμε πως με εντολές από την βιβλιοθήκη Pytorch χτίζουμε μια οικογένεια νευρωνικών.</em></p>

    <p><a href="/pdfs/mlclass/L11.pdf">Διαφάνειες</a></p>
  </li>
  <li>
    <p><strong>Lecture 12: <a href="https://youtu.be/yrDRb_nLoFc">Νευρωνικά Δίκτυα: Feedforward 1/2 (Python / Colab)</a></strong><br />
<img src="/images/mlclass/L12.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Σε αυτήν την διάλεξη αρχίζουμε την εξερεύνηση των νευρωνικών δικτύων με την βιβλιοθήκη Pytorch. Χτίζουμε νευρωνικά με fully-connected επίπεδα και με ReLU. Προς το παρόν δεν εκπαιδεύουμε ακόμα το νευρωνικό – αλλά επιλέγοντας τιμές για τις παραμέτρους, βλέπουμε με λεπτομέρεια (και με κώδικα) πως κάνει υπολογισμούς, δηλαδή, πως παίρνει δεδομένα και παράγει τις προβλέψεις (τα output).</em></p>

    <p><a href="https://colab.research.google.com/drive/1xDZPLPtRaBPZIH0XszO8egUq-OSlBz-8?usp=sharing">Colab Notebook</a></p>
  </li>
  <li>
    <p><strong>Lecture 13: <a href="https://youtu.be/yrDRb_nLoFc">Νευρωνικά Δίκτυα: Feedforward 2/2 (Python / Colab)</a></strong><br />
<img src="/images/mlclass/L13.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Συνεχίζουμε την συζήτησή μας για νευρωνικά δίκτυα, χρησιμοποιώντας την Pytorch. Εξηγούμε πως δουλεύει το softmax και γιατί το χρειαζόμαστε, και ύστερα βλέπουμε πως λειτουργεί ένα απλό νευρωνικό δίκτυο σε ένα δισδιάστατο πρόβλημα ταξινόμησης. Επίσης οπτικοποιούμε ισοϋψείς καμπήλες για να καταλάβουμε σε μεγαλύτερο βάθος την συμπεριφορά του νευρωνικού δικτύου, και γιατί τα ReLU είναι απαραίτητα.</em></p>

    <p><a href="https://colab.research.google.com/drive/1EVNEGakrtSQTHcUdO_lYJPSIPMHEjJZb?usp=sharing">Colab Notebook</a></p>
  </li>
  <li>
    <p><strong>Lecture 14: <a href="https://youtu.be/yrDRb_nLoFc">Εκπαίδευση Νευρωνικών Δικτύων (Python / Colab)</a></strong><br />
<img src="/images/mlclass/L14.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Σε αυτήν την διάλεξη συζητάμε την εκπαίδευση νευρωνικών δικτύων με την Pytorch. Στην πορεία, συναντάμε κάποια βασικά εργαλεία της Pytorch: τα Data Loaders, και τα Transforms. Επίσης, συζητάμε σε διαισθητικό επίπεδο, τι κάνει ο κώδικας της εκπαίδευσης στην Pytorch, ποιός είναι ο ρόλος του optimizer και του scheduler.</em></p>

    <p><a href="https://colab.research.google.com/drive/1hCXEaMOxXnxWPoPn9YYufDF2huHUgHAS?usp=sharing">Colab Notebook</a></p>
  </li>
</ul>

<p>`</p>
<h3 id="module-5-μηχανική-όραση-και-συνελικτικά-νευρωνικά-δίκτυα-convolutional-neural-networks">Module 5: Μηχανική Όραση και Συνελικτικά Νευρωνικά Δίκτυα (Convolutional Neural Networks)</h3>

<ul>
  <li>
    <p><strong>Lecture 15: <a href="https://youtu.be/ylFgsqWn7ws">Μηχανική Όραση</a></strong><br />
<img src="/images/mlclass/L15.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Σε αυτήν την διάλεξη περιγράφουμε πως αποθηκεύονται οι μαυρόασπρες και οι έγχρωμες εικόνες στον υπολογιστή, και έτσι αρχίζουμε την συζήτησή μας για την Μηχανική Όραση (Computer Vision).</em></p>

    <p><a href="/pdfs/mlclass/L15.pdf">Διαφάνειες</a></p>
  </li>
  <li>
    <p><strong>Lecture 16: <a href="https://youtu.be/7xVFFdGkAYw">Convolutional Neural Networks</a></strong><br />
<img src="/images/mlclass/L16.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Συνεχίζουμε την συζήτησή μας για την Μηχανική Όραση (Computer Vision) και εξηγούμε λεπτομερώς τι είναι, γιατί τα χρειαζόμαστε, και πως χρησιμοποιούνται τα συνελικτικά επίπεδα και νευρωνικά δίκτυα (Convolutional Neural Networks).</em></p>

    <p><a href="/pdfs/mlclass/L16.pdf">Διαφάνειες</a></p>
  </li>
  <li>
    <p><strong>Lecture 17: <a href="https://youtu.be/vLtPZvbRY_w">Convolutional Neural Networks &amp; MNIST (Python / Colab)</a></strong><br />
<img src="/images/mlclass/L17.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Σε αυτήν την διάλεξη υλοποιούμε με την Python &amp; Pytorch τις ιδέες που έχουμε δεί – συγκεκριμένα, τα συνελικτικά νευρωνικά δίκτυα (convolutional neural networks) – για την αυτόματη αναγνώριση χειρόγραφων ψηφίων. Χρησιμοποιούμε το σετ δεδομένων MNIST.</em></p>

    <p><a href="https://colab.research.google.com/drive/1SHuJTmahC6w-KoMrcMm4IppIJ3Ycut5H?usp=sharing`">Colab Notebook</a></p>
  </li>
  <li>
    <p><strong>Lecture 18: <a href="https://youtu.be/Hcv0JuIoYcM">Convolutional Neural Networks &amp; CIFAR-10 (Python / Colab)</a></strong><br />
<img src="/images/mlclass/L18.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Σε αυτήν την διάλεξη επιστρέφουμε στα σετ δεδομένων του CIFAR-10. Με τα δέντρα αποφασης, είχαμε καταφέρει να πετύχουμε ακρίβεια (στα δεδομένα εκτίμησης) γύρω στο 23%-24%. Χρησιμοποιώντας βαθιά νευρωνικά δίκτυα με convolutional επίπεδα (CNNs), βελτιώνουμε πολύ την επίδοσή μας. Χτίζουμε τρία δίκτυα. Το μικρότερο έχει περίπου 2.500 παραμέτρους. Το μεσαίο περίπου 60.000. Και το μεγαλύτερο σχεδόν 6.000.000. Τα εκπαιδεύουμε όλα, και βλέπουμε την επίδοσή τους.</em></p>

    <p><a href="https://colab.research.google.com/drive/1PMhVak3v8e5nCcvQEEGvBNdcLalYcCeW?usp=drive_link">Colab Notebook</a></p>
  </li>
</ul>

<p>`</p>
<h3 id="module-6-transfer-learning">Module 6: Transfer Learning</h3>

<ul>
  <li>
    <p><strong>Lecture 19: <a href="">Transfer Learning στην Μηχανική Όραση</a></strong><br />
<img src="/images/mlclass/L18.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Σε αυτήν την διάλεξη εισάγουμε την θεμελιώδη ιδέα του Transfer Learning, και εξηγούμε πως εφαρμόζεται σε προβλήματα της Μηχανικής Όρασης.</em></p>

    <p><a href="/pdfs/mlclass/L19.pdf">Διαφάνειες</a></p>
  </li>
  <li>
    <p><strong>Lecture 20: <a href="">Transfer Learning: Resnet18 και CIFAR-10 (Python / Colab)</a></strong><br />
<img src="/images/mlclass/L18.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Σε αυτήν την διάλεξη επιστρέφουμε για μια τελευταία φορά στο σετ δεδομένων CIFAR-10, και χρησιμοποιούμε την ιδέα του Transfer Learning. Χρησιμοποιώντας ένα βαθύ νευρωνικό δίκτυο προεκπαιδευμένο στις 14.000.000 εικόνες του Imagenet, καταφέρνουμε να ξεπεράσουμε τις επιδόσεις των νευρωνικών που εκπαιδεύσαμε εξαρχής, μόνο με τα δεδομένα του CIFAR-10.”</em></p>
  </li>
  <li>
    <p><strong>Lecture 21: <a href="">Transfer Learning: Υπερηχογραφήματα (Python / Colab)</a></strong><br />
<img src="/images/mlclass/L18.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Σε αυτήν την διάλεξη εφαρμόζουμε το Transfer Learning στο πρόβλημα της ταξινόμησης υπερηχογραφημάτων, για την ανίχνευση του καρκίνου του μαστού.</em></p>
  </li>
</ul>

<hr />


    </div>
    
  </body>
</html>
