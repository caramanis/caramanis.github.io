<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Μηχανική Μάθηση και Τεχνητή Νοημοσύνη &middot; Constantine Caramanis
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body>

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h2>
        Constantine Caramanis
      </h2>
      <p class="lead"></p>
    </div>

    <nav class="sidebar-nav">


      

      <a class="sidebar-nav-item" href="/">Home</a>
      <a class="sidebar-nav-item" href="/teaching/">Teaching</a>
      <a class="sidebar-nav-item" href="/publications/">Publications</a>
      <a class="sidebar-nav-item" href="/researchgroup/">Research Group</a>
      <a class="sidebar-nav-item" href="/researchprojects/">Research Projects</a>
      <a class="sidebar-nav-item" href="https://scholar.google.com/citations?user=47YTUrEAAAAJ&hl=en&oi=ao" target="_blank">Google Scholar</a>
      <a class="sidebar-nav-item" href="https://www.youtube.com/channel/UCSv1_NZITsPl-abaCWtRrJg" target="_blank">YouTube</a>
      <a class="sidebar-nav-item" href="https://ml.utexas.edu/ifml" target="_blank">IFML</a>
      <a class="sidebar-nav-item" href="https://wncg.org" target="_blank">WNCG</a>
      <a class="sidebar-nav-item" href="https://archimedesai.gr/en/" target="_blank">Archimedes AI</a>




      <!--<span class="sidebar-nav-item">Jekyll Hyde, Currently v2.1.0</span>-->
    </nav>

    <p>&copy; 2025. All rights reserved.</p> 
  </div>
</div>


    <div class="content container">
      <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 20px;">
  <img src="/images/mlclass/logo_archimedes_arc.jpg" alt="Left Logo" style="height: 50px;" />
  <img src="/images/mlclass/for_site_logo_en.jpg" alt="Right Logo" style="height: 50px;" />
</div>

<h1 id="μηχανική-μάθηση-και-τεχνητή-νοημοσύνη">Μηχανική Μάθηση και Τεχνητή Νοημοσύνη</h1>

<hr />

<p><span style="font-size: 16px;">Καλωσορίσατε στο μάθημα Τεχνητής Nοημοσύνης και Μηχανικής Μάθησης (Machine Learning). Σε αυτές τις διαλέξεις θα καλύψουμε τις βασικές και θεμελιώδεις ιδέες της Μηχανικής Μάθησης. Θα αρχίσουμε με την επιτηρούμενη μάθηση (supervised learning), και θα φτάσουμε εώς τα νευρωνικά δίκτυα (neural networks) και την τεχνική του Transfer Learning. Τα μαθήματα βασίζονται σε υλικό που έχω αναπτύξει στο Πανεπιστήμιο του Τέξας στο Ώστιν (UT Austin). Απευθύνονται σε μαθητές του λυκείου που έχουν κάποια γνώση προγραμματισμού και που ενδιαφέρονται να μάθουν τις βασικές αρχές της Μηχανικής Μάθησης.<br />
<br />
Αυτό το μάθημα δεν επιδιώκει να αναπτύξει μία ολοκληρωμένη βάση των ιδεών και των αλγορίθμων της μηχανικής μάθησης, αλλά μάλλον να χτίσει έναν βασικό πυρήνα των ιδεών, ο οποίος μπορεί να επεκταθεί εύκολα, αλλά και να χρησιμοποιηθεί άμεσα. Σκοπός μας είναι να προχωρήσουμε γρήγορα τόσο με τις βασικές ιδέες, όσο και με την υλοποίησή τους στην γλώσσα Python και στις βασικές της βιβλιοθήκες, ώστε να μπορείτε να τις εφαρμόσετε και μόνοι σας σε πρότζεκτ και προβλήματα που κεντρίζουν το δικό σας ενδιαφέρον.<br />
<br />
Θα βρείτε παρακάτω λινκς σε μια σειρά από διαλέξεων, οργανωμένα θεματικά σε “Modules”. Χρησιμοποιούμε διαφάνειες όταν πρωτοεισάγουμε και εξηγούμε μία καινούργια ιδέα. Στις επόμενες διαλέξεις, αναπτύσσουμε και υλοποιούμε αυτές τις ιδέες στην Python, για να βρούμε λύσεις σε προβλήματα της μηχανικής μάθησης, με πραγματικά και επίσης τεχνητά δεδομένα.<br />
<br />
Python και Colab: θα χρησιμοποιήσουμε την γλώσσα προγραμματισμού Python. Δεν καλύπτουμε τις αρχές της Python από το μηδέν. Ωστόσο, στις διαλέξεις εξηγούμε τις βασικές εντολές, και δίνουμε πληροφορίες για τις βιβλιοθήκες που χρησιμοποιούμε. Επίσης σε διάφορα σημείεα του κώδικα, σας προτείνω κάποια λινκς που περιέχουν παραπάνω λεπτομέρειες για τις συγκεκριμένες εντολές ή βιβλιοθήκες, που μπορείτε να ακολουθήσετε ώστε να εμβαθύνετε τις γνώσεις σας. Όλος ο προγραμματισμός θα γίνει στο <strong>Colab</strong>. Το Colab είναι ένα δωρεάν, βασισμένο στο cloud εργαλείο από την Google, το οποίο επιτρέπει τη συγγραφή και την εκτέλεση κώδικα Python σε περιβάλλον Jupyter Notebook. Δουλεύει εξ ολοκλήρου στον browser, χωρίς να απαιτείται εγκατάσταση λογισμικού ή ρύθμιση περιβάλλοντος, οπότε η χρήση του μας εξασφαλίζει πως όλοι έχουμε πρόσβαση στο ίδιο υπολογιστικό περιβάλλον. <em>Θα χρειαστείτε όμως λογαριασμό</em> <strong>gmail</strong>.<br />
<br />
Πως μπορείτε να χρησιμοποιήσετε την ύλη του μαθήματος:  </span>
<br />
<br /></p>
<div style="font-size: 16px;">
1. Οι διαλέξεις είναι σχεδιασμένες να τις παρακολουθείσετε με την σειρά, μαζί με το υλικό, δηλαδή, τις διαφάνειες ή τα Colab Notebook.  
<br />
2. Εάν θέλετε να πάρετε μια γρήγορη συνολική ιδέα του τι καλύπτει το μάθημα, μπορείτε να παρακολουθήσετε μόνο τα μαθήματα με διαφάνειες. Τα μαθήματα όπου υλοποιούμε αλγορίθμους σε Python έχουν στον τίτλο την επισήμανση "(Python / Colab)".  
<br />
3. Εάν έχετε ήδη εμπειρία χρησιμοποιώντας την Python και έχετε κάποια επαφή με τις ιδέες και τους αλγορίθμους της μηχανικής μάθησης, μπορείτε απλά να πάτε κατευθείαν στα Colab Notebooks που σας ενδιαφέρουν.  
<br />
4. Αυτά τα μαθήματα αποτελούν έναν βασικό κορμό ή πυρήνα, και σκοπός είναι να επεκταθεί. Όταν είναι έτοιμες καινούργιες διαλέξεις, θα τις βρείτε εδώ.
</div>

<hr />

<h3 id="εδώ-θα-βρείτε-λινκς-για-την-πλήρη-ύλη-του-μαθήματος"><strong>Εδώ θα βρείτε λινκς για την πλήρη ύλη του μαθήματος</strong>:</h3>

<ol>
  <li><a href="https://www.youtube.com/playlist?list=PLXsmhnDvpjOSYdEt3QjLeFSQPoZrR3XJg" target="_blank" rel="noopener noreferrer" style="font-size: 16px;"><b>Βιντεοσκοπημένα μαθήματα</b></a>
<br /></li>
  <li><a href="/pdfs/mlclass/LectureSlides.zip" style="font-size: 16px;" download=""><b>Διαφάνειες</b></a> 
<br /></li>
  <li><a href="https://colab.research.google.com/drive/12fEpyjWshpdqG4XaPKSpO9EYqtag4-zy?usp=sharing" target="_blank" rel="noopener noreferrer" style="font-size: 16px;"><b>Colab Notebooks σε Python</b></a></li>
</ol>

<hr />

<p>`</p>
<h3 id="module-1-εισαγωγή-στο-μάθημα-και-στην-τεχνητή-νοημοσύνη">Module 1: Εισαγωγή στο Μάθημα και στην Τεχνητή Νοημοσύνη</h3>

<ul>
  <li>
    <p><strong>Lecture 1: <a href="https://youtu.be/KxUD5Rc149Y" target="_blank" rel="noopener noreferrer">Τι είναι η Τεχνητή Νοημοσύνη; Τι θα καλύψει αυτό το μάθημα;</a></strong>
<img src="/images/mlclass/L01.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Σε αυτήν την διάλεξη δίνουμε κάποια πρώτα παραδείγματα, και ύστερα περιγράφουμε συνοπτικά όλο το μάθημα, την δομή των διαλέξεων, και τις προαπαιτούμενες γνώσεις για να παρακολουθήσετε τα μαθήματα.</em></p>

    <p><a href="/pdfs/mlclass/L01.pdf" target="_blank" rel="noopener noreferrer">Διαφάνειες</a></p>
  </li>
  <li>
    <p><strong>Lecture 2: <a href="https://youtu.be/lvTMKTXzjwk" target="_blank" rel="noopener noreferrer">Ο John Snow, η Χολέρα, και η Μοντέρνα Τεχνητή Νοημοσύνη</a></strong>
<img src="/images/mlclass/L02.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Σε αυτήν την διάλεξη συνεχίζουμε την συζήτησή μας για την τεχνητή νοημοσύνη. Αρχίζουμε με ένα ιστορικό παράδειγμα, και ύστερα περνάμε σε παραδείγματα εφαρμογών της μοντέρνας μηχανικής μάθησης. Με αυτόν τον τρόπο εξηγούμε την ιδέα της ταξινόμησης και παλινδρόμησης στην μηχανική όραση και στην επεξεργασία φυσικής γλώσσας. Επίσης συζητάμε την γενετική τεχνητή νοημοσύνη και κάποιες εφαρμογές.</em></p>

    <p><a href="/pdfs/mlclass/L02.pdf" target="_blank" rel="noopener noreferrer">Διαφάνειες</a></p>
  </li>
</ul>

<p>`</p>
<h3 id="module-2-επιτηρούμενη-μάθηση-supervised-learning">Module 2: Επιτηρούμενη Μάθηση (Supervised Learning)</h3>

<ul>
  <li>
    <p><strong>Lecture 3: <a href="https://youtu.be/R-05LXetsFw" target="_blank" rel="noopener noreferrer">Επιτηρούμενη Μάθηση και Δέντρα Απόφασης</a></strong>
<img src="/images/mlclass/L03.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Σε αυτήν την διάλεξη συζητάμε την βασική ιδέα του αλγορίθμου, και των παραμέτρων. Βασικός μας στόχος είναι να περιγράψουμε το βασικό πρότυπο της επιτηρούμενης μάθησης – supervised learning. Θα εξηγήσουμε τι θα πεί “εκπαιδεύω αλγόριθμο”. Η επόμενη διάλεξη μπαίνει λεπτομερώς στην υλοποίηση (με κώδικα) της επιτηρούμενης μάθησης στην Python.</em></p>

    <p><a href="/pdfs/mlclass/L03.pdf" target="_blank" rel="noopener noreferrer">Διαφάνειες</a></p>
  </li>
  <li>
    <p><strong>Lecture 4: <a href="https://youtu.be/tiEXSzf1Jcs" target="_blank" rel="noopener noreferrer">Δέντρα Απόφασης με δεδομένα του διαβήτη 1/2 (Python / Colab)</a></strong>
<img src="/images/mlclass/L04.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Σε αυτήν την διάλεξη, υλοποιούμε τις βασικές ιδέες στην Python. Μεταφορτώνουμε ένα σετ δεδομένων σχετικά με τον διαβήτη. Χρησιμοποιούμε εντολές της Pandas, την Numpy και της Matplotlib για να επεξεργαστούμε, να οπτικοποιήσουμε και να καθαρίσουμε τα δεδομένα. Ύστερα, χρησιμοποιούμε εντολές από την βιβλιοθήκη Sklearn για να εκπαιδεύσουμε δέντρα απόφασης.</em></p>

    <p><a href="https://colab.research.google.com/drive/162hNnEDlmoAzcNFhEMQFmMXFQeVPHgHr?usp=drive_link" target="_blank" rel="noopener noreferrer">Colab Notebook</a></p>
  </li>
  <li>
    <p><strong>Lecture 5: <a href="https://youtu.be/0VJXJOOMrhQ" target="_blank" rel="noopener noreferrer">Δέντρα Απόφασης με δεδομένα του διαβήτη 2/2 (Python / Colab)</a></strong>
<img src="/images/mlclass/L05.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Σε αυτήν την διάλεξη συμπληρώνουμε τις ασκήσεις που είχαμε περιγράψει στην προηγούμενη διάλεξη.</em></p>

    <p><a href="https://colab.research.google.com/drive/162hNnEDlmoAzcNFhEMQFmMXFQeVPHgHr?usp=sharing" target="_blank" rel="noopener noreferrer">Colab Notebook</a></p>
  </li>
</ul>

<p>`</p>
<h3 id="module-3-υπερμοντελοποίηση-και-υπομοντελοποίηση-overfitting-and-underfitting">Module 3: Υπερμοντελοποίηση και Υπομοντελοποίηση (Overfitting and Underfitting)</h3>

<ul>
  <li>
    <p><strong>Lecture 6: <a href="https://youtu.be/hsNyHqZkKbg" target="_blank" rel="noopener noreferrer">Υπερμοντελοποίηση:  οι βασικές ιδέες</a></strong>
<img src="/images/mlclass/L06.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Σε αυτήν την διάλεξη αρχίζουμε την συζήτησή μας για την υπερμοντελοποίηση (overfitting). Η υπερμοντελοποίηση περιγράφει το φαινόμενο όπου ένας αλγόριθμος ταιριάζει πολύ καλά (έχει μεγάλη ακρίβεια) στα δεδομένα με τα οποία εκπαιδεύτηκε, αλλά έχει πολύ χειρότερη επίδοση (ακρίβεια) σε δεδομένα που δεν περιέχονται στα δεδομένα εκπαίδευσης. Αυτό συμβαίνει, όπως είδαμε, με τα δεδομένα του διαβήτη όταν εκπαιδεύουμε βαθιά δέντρα απόφασης.</em></p>

    <p><a href="/pdfs/mlclass/L06.pdf" target="_blank" rel="noopener noreferrer">Διαφάνειες</a></p>
  </li>
  <li>
    <p><strong>Lecture 7: <a href="https://youtu.be/7xRt4mJ8vmU" target="_blank" rel="noopener noreferrer">Υπερμοντελοποίηση στην Python (Python / Colab)</a></strong>
<img src="/images/mlclass/L07.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Συνεχίζουμε την συζήτησή μας για την υπερμοντελοποίηση, τώρα παρατηρώντας αυτό το φαινόμενο στην πράξη. Κοιτάμε πάλι τα δεδομένα του διαβήτη. Δημιουργούμε ένα τεχνητό σετ δεδομένων, και πάλι με βαθιά δέντρα απόφασης, παρατηρούμε και εκεί το φαινόμενο της υπερμοντελοποίησης: τα βαθιά δέντρα απόφασης υπερμοντελοποιούν διότι προσπαθούν να μοντελοποιήσουν τον θόρυβο στα δεδομένα εκπαίδευσης.</em></p>

    <p><a href="https://colab.research.google.com/drive/1WZ4ho2InMZksR-2GINRJfxiAKMnk1ryT?usp=drive_link" target="_blank" rel="noopener noreferrer">Colab Notebook</a></p>
  </li>
  <li>
    <p><strong>Lecture 8: <a href="https://youtu.be/XmD9Zxs9JBE" target="_blank" rel="noopener noreferrer">Υπερμοντελοποίηση με το CIFAR-10 (Python / Colab)</a></strong>
<img src="/images/mlclass/L08.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Σε αυτήν την διάλεξη συνεχίζουμε την συζήτηση για την υπερμοντελοποίηση και τα δέντρα απόφασης, τώρα με ένα πρόβλημα ταξινόμησης στην Μηχανική Όραση (computer vision), με τα δεδομένα του CIFAR-10. Είναι αφορμή να μάθουμε πως αποθηκεύονται οι εικόνες στον υπολογιστή, και επίσης να δούμε ένα πρόβλημα σημαντικά μεγαλύτερο από αυτά που έχουμε δεί εώς τώρα.</em></p>

    <p><a href="https://colab.research.google.com/drive/1qv3oE3adlxBuLl6H2jHzj4UvLKw96qPf?usp=drive_link" target="_blank" rel="noopener noreferrer">Colab Notebook</a></p>
  </li>
  <li>
    <p><strong>Lecture 9: <a href="https://youtu.be/K4ChsxSLPq0" target="_blank" rel="noopener noreferrer">Υπερμοντελοποίηση και Υπομονετλοποίηση στην Παλινδρόμηση (Python / Colab)</a></strong>
<img src="/images/mlclass/L09.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Σε αυτήν την διάλεξη ξανασυνταντάμε τις βασικές ιδέες που έχουμε αναπτύξει στο μάθημα, αλλά με προβλήματα παλινδρόμησης (regression). Συγκεκριμένα, συζητάμε το βασικό πρότυπο της επιτηρούμενης μάθησης και εκπαίδευσης αλγορίθμων, και την υπερμοντελοποίηση (overfitting). Επίσης, εξηγούμε την ιδέα της υπομοντελοποίησης (underfitting).</em></p>

    <p><a href="https://colab.research.google.com/drive/1gVhD4oqLVCGFTkL1JO6JDt2VpuDIOfNQ?usp=drive_link" target="_blank" rel="noopener noreferrer">Colab Notebook</a></p>
  </li>
</ul>

<p>`</p>
<h3 id="module-4-νευρωνικά-δίκτυα-neural-networks">Module 4: Νευρωνικά Δίκτυα (Neural Networks)</h3>

<ul>
  <li>
    <p><strong>Lecture 10: <a href="https://youtu.be/yrDRb_nLoFc" target="_blank" rel="noopener noreferrer">Εισαγωγή στα Νευρωνικά Δίκτυα</a></strong>
<img src="/images/mlclass/L10.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Σε αυτήν την διάλεξη αρχίζουμε την συζήτησή μας για βαθιά νευρωνικά δίκτυα (deep neural networks). Εξηγούμε δύο από τα βασικά δομικά στοιχεία των νευρωνικών δικτύων: τα fully-connected γραμμικά επίπεδα (fully connected layers), και το softmax.</em></p>

    <p><a href="/pdfs/mlclass/L10.pdf" target="_blank" rel="noopener noreferrer">Διαφάνειες</a></p>
  </li>
  <li>
    <p><strong>Lecture 11: <a href="https://youtu.be/M9766Zd4Okg" target="_blank" rel="noopener noreferrer">Νευρωνικά Δίκτυα: ReLU</a></strong>
<img src="/images/mlclass/L11.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Συνεχίζουμε την συζήτησή μας για νευρωνικά δίτκυα. Απαντάμε την ερώτηση που έθεσε η προηγούμενη διάλεξη: ‘αρκούν τα γραμμικά επίπεδα για να χτίσουμε μια πλούσια οικογένεια νευρωνικών δικτύων;’ Βλέπουμε με ένα απλό παράδειγμα και υπολογισμό, πως δεν μπορούμε να βασιστούμε μόνο σε γραμμικά επίπεδα: δύο (ή και παραπάνω) γραμμικά επίπεδα στην σειρά, ισοδυναμούν με μόνο ένα γραμμικό επίπεδο. Είναι απαραίτητα, λοιπόν, κάποια μη-γραμμικά επίπεδα: τα ReLU (ή κάτι παρόμοιο). Ύστερα, εξηγούμε πως με εντολές από την βιβλιοθήκη Pytorch χτίζουμε μια οικογένεια νευρωνικών.</em></p>

    <p><a href="/pdfs/mlclass/L11.pdf" target="_blank" rel="noopener noreferrer">Διαφάνειες</a></p>
  </li>
  <li>
    <p><strong>Lecture 12: <a href="https://youtu.be/ItNmhomedKo" target="_blank" rel="noopener noreferrer">Νευρωνικά Δίκτυα: Feedforward 1/2 (Python / Colab)</a></strong>
<img src="/images/mlclass/L12.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Σε αυτήν την διάλεξη αρχίζουμε την εξερεύνηση των νευρωνικών δικτύων με την βιβλιοθήκη Pytorch. Χτίζουμε νευρωνικά με fully-connected επίπεδα και με ReLU. Προς το παρόν δεν εκπαιδεύουμε ακόμα το νευρωνικό – αλλά επιλέγοντας τιμές για τις παραμέτρους, βλέπουμε με λεπτομέρεια (και με κώδικα) πως κάνει υπολογισμούς, δηλαδή, πως παίρνει δεδομένα και παράγει τις προβλέψεις (τα output).</em></p>

    <p><a href="https://colab.research.google.com/drive/1xDZPLPtRaBPZIH0XszO8egUq-OSlBz-8?usp=sharing" target="_blank" rel="noopener noreferrer">Colab Notebook</a></p>
  </li>
  <li>
    <p><strong>Lecture 13: <a href="https://youtu.be/oNXzaGlpdRU" target="_blank" rel="noopener noreferrer">Νευρωνικά Δίκτυα: Feedforward 2/2 (Python / Colab)</a></strong>
<img src="/images/mlclass/L13.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Συνεχίζουμε την συζήτησή μας για νευρωνικά δίκτυα, χρησιμοποιώντας την Pytorch. Εξηγούμε πως δουλεύει το softmax και γιατί το χρειαζόμαστε, και ύστερα βλέπουμε πως λειτουργεί ένα απλό νευρωνικό δίκτυο σε ένα δισδιάστατο πρόβλημα ταξινόμησης. Επίσης οπτικοποιούμε ισοϋψείς καμπήλες για να καταλάβουμε σε μεγαλύτερο βάθος την συμπεριφορά του νευρωνικού δικτύου, και γιατί τα ReLU είναι απαραίτητα.</em></p>

    <p><a href="https://colab.research.google.com/drive/1EVNEGakrtSQTHcUdO_lYJPSIPMHEjJZb?usp=sharing" target="_blank" rel="noopener noreferrer">Colab Notebook</a></p>
  </li>
  <li>
    <p><strong>Lecture 14: <a href="https://youtu.be/c4Fyij73nBI" target="_blank" rel="noopener noreferrer">Εκπαίδευση Νευρωνικών Δικτύων (Python / Colab)</a></strong>
<img src="/images/mlclass/L14.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Σε αυτήν την διάλεξη συζητάμε την εκπαίδευση νευρωνικών δικτύων με την Pytorch. Στην πορεία, συναντάμε κάποια βασικά εργαλεία της Pytorch: τα Data Loaders, και τα Transforms. Επίσης, συζητάμε σε διαισθητικό επίπεδο, τι κάνει ο κώδικας της εκπαίδευσης στην Pytorch, ποιός είναι ο ρόλος του optimizer και του scheduler.</em></p>

    <p><a href="https://colab.research.google.com/drive/1hCXEaMOxXnxWPoPn9YYufDF2huHUgHAS?usp=sharing" target="_blank" rel="noopener noreferrer">Colab Notebook</a></p>
  </li>
</ul>

<p>`</p>
<h3 id="module-5-μηχανική-όραση-και-συνελικτικά-νευρωνικά-δίκτυα-convolutional-neural-networks">Module 5: Μηχανική Όραση και Συνελικτικά Νευρωνικά Δίκτυα (Convolutional Neural Networks)</h3>

<ul>
  <li>
    <p><strong>Lecture 15: <a href="https://youtu.be/ylFgsqWn7ws" target="_blank" rel="noopener noreferrer">Μηχανική Όραση</a></strong>
<img src="/images/mlclass/L15.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Σε αυτήν την διάλεξη περιγράφουμε πως αποθηκεύονται οι μαυρόασπρες και οι έγχρωμες εικόνες στον υπολογιστή, και έτσι αρχίζουμε την συζήτησή μας για την Μηχανική Όραση (Computer Vision).</em></p>

    <p><a href="/pdfs/mlclass/L15.pdf" target="_blank" rel="noopener noreferrer">Διαφάνειες</a></p>
  </li>
  <li>
    <p><strong>Lecture 16: <a href="https://youtu.be/7xVFFdGkAYw" target="_blank" rel="noopener noreferrer">Convolutional Neural Networks</a></strong>
<img src="/images/mlclass/L16.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Συνεχίζουμε την συζήτησή μας για την Μηχανική Όραση (Computer Vision) και εξηγούμε λεπτομερώς τι είναι, γιατί τα χρειαζόμαστε, και πως χρησιμοποιούνται τα συνελικτικά επίπεδα και νευρωνικά δίκτυα (Convolutional Neural Networks).</em></p>

    <p><a href="/pdfs/mlclass/L16.pdf" target="_blank" rel="noopener noreferrer">Διαφάνειες</a></p>
  </li>
  <li>
    <p><strong>Lecture 17: <a href="https://youtu.be/vLtPZvbRY_w" target="_blank" rel="noopener noreferrer">Convolutional Neural Networks &amp; MNIST (Python / Colab)</a></strong>
<img src="/images/mlclass/L17.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Σε αυτήν την διάλεξη υλοποιούμε με την Python &amp; Pytorch τις ιδέες που έχουμε δεί – συγκεκριμένα, τα συνελικτικά νευρωνικά δίκτυα (convolutional neural networks) – για την αυτόματη αναγνώριση χειρόγραφων ψηφίων. Χρησιμοποιούμε το σετ δεδομένων MNIST.</em></p>

    <p><a href="https://colab.research.google.com/drive/1SHuJTmahC6w-KoMrcMm4IppIJ3Ycut5H?usp=sharing`" target="_blank" rel="noopener noreferrer">Colab Notebook</a></p>
  </li>
  <li>
    <p><strong>Lecture 18: <a href="https://youtu.be/Hcv0JuIoYcM" target="_blank" rel="noopener noreferrer">Convolutional Neural Networks &amp; CIFAR-10 (Python / Colab)</a></strong>
<img src="/images/mlclass/L18.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Σε αυτήν την διάλεξη επιστρέφουμε στο σετ δεδομένων του CIFAR-10. Με τα δέντρα αποφασης, είχαμε καταφέρει να πετύχουμε ακρίβεια (στα δεδομένα εκτίμησης) γύρω στο 23%-24%. Χρησιμοποιώντας βαθιά νευρωνικά δίκτυα με convolutional επίπεδα (CNNs), βελτιώνουμε πολύ την επίδοσή μας. Χτίζουμε τρία δίκτυα. Το μικρότερο έχει περίπου 2.500 παραμέτρους. Το μεσαίο περίπου 60.000. Και το μεγαλύτερο σχεδόν 6.000.000. Τα εκπαιδεύουμε όλα, και βλέπουμε την επίδοσή τους.</em></p>

    <p><a href="https://colab.research.google.com/drive/1PMhVak3v8e5nCcvQEEGvBNdcLalYcCeW?usp=drive_link" target="_blank" rel="noopener noreferrer">Colab Notebook</a></p>
  </li>
</ul>

<p>`</p>
<h3 id="module-6-transfer-learning">Module 6: Transfer Learning</h3>

<ul>
  <li>
    <p><strong>Lecture 19: <a href="https://youtu.be/1TNZHy6ZurU" target="_blank" rel="noopener noreferrer">Transfer Learning στην Μηχανική Όραση</a></strong>
<img src="/images/mlclass/L19.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Σε αυτήν την διάλεξη εισάγουμε την θεμελιώδη ιδέα του Transfer Learning, και εξηγούμε πως εφαρμόζεται σε προβλήματα της Μηχανικής Όρασης.</em></p>

    <p><a href="/pdfs/mlclass/L19.pdf" target="_blank" rel="noopener noreferrer">Διαφάνειες</a></p>
  </li>
  <li>
    <p><strong>Lecture 20: <a href="https://youtu.be/0NfdJbMd3eM" target="_blank" rel="noopener noreferrer">Transfer Learning: Resnet18 και CIFAR-10 (Python / Colab)</a></strong>
<img src="/images/mlclass/L20.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Σε αυτήν την διάλεξη επιστρέφουμε για μια τελευταία φορά στο σετ δεδομένων CIFAR-10, και χρησιμοποιούμε την ιδέα του Transfer Learning. Χρησιμοποιώντας ένα βαθύ νευρωνικό δίκτυο προεκπαιδευμένο στις 14.000.000 εικόνες του Imagenet, καταφέρνουμε να ξεπεράσουμε τις επιδόσεις των νευρωνικών που εκπαιδεύσαμε εξαρχής, μόνο με τα δεδομένα του CIFAR-10.”</em></p>

    <p><a href="https://colab.research.google.com/drive/1tnIQoViTVbT-7XiJa791h492B_WuNw4t?usp=sharing" target="_blank" rel="noopener noreferrer">Colab Notebook</a></p>
  </li>
  <li>
    <p><strong>Lecture 21: <a href="https://youtu.be/C37Z7bONGHA" target="_blank" rel="noopener noreferrer">Transfer Learning: Υπερηχογραφήματα (Python / Colab)</a></strong>
<img src="/images/mlclass/L21.png" alt="Lecture Thumbnail" style="width: 300px; height: auto;" />
<em>Σε αυτήν την διάλεξη εφαρμόζουμε την τεχνική του Transfer Learning σε ένα πρόβλημα ιατρικής απεικόνισης: προσπαθούμε να ανιχνεύσουμε τον καρκίνο μαστού από υπερηχογραφήματα, χρησιμοποιώντας ένα σετ δεδομένων από την Kaggle (https://www.kaggle.com/). Εξετάζουμε πως λειτουργεί το Transfer Learning χρησιμοποιώντας δύο διαφορετικά βαθιά νευρωνικά δίκτυα προεκπαιδευμένα στο ImagNet: το Resnet18 και το Inception V3. Μαθαίνουμε επίσης για την τεχνική του Data Augmentation (Αύξηση Δεδομένων), πως εφαρμόζεται και σε τι χρησιμεύει.</em></p>

    <p><a href="https://colab.research.google.com/drive/1Slmo9U12kZXqA_xN6sehVL54MTVyWMrR?usp=sharing" target="_blank" rel="noopener noreferrer">Colab Notebook</a></p>
  </li>
</ul>

<hr />


    </div>
    
  </body>
</html>
