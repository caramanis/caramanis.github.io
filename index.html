<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
       &middot; Constantine Caramanis
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body>

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h2>
        Constantine Caramanis
      </h2>
      <p class="lead"></p>
    </div>

    <nav class="sidebar-nav">


      

      <a class="sidebar-nav-item active" href="/">Home</a>
      <a class="sidebar-nav-item" href="/teaching/">Teaching</a>
      <a class="sidebar-nav-item" href="/publications/">Publications</a>
      <a class="sidebar-nav-item" href="/researchgroup/">Research Group</a>
      <a class="sidebar-nav-item" href="/researchprojects/">Research Projects</a>
      <a class="sidebar-nav-item" href="https://scholar.google.com/citations?user=47YTUrEAAAAJ&hl=en&oi=ao" target="_blank">Google Scholar</a>
      <a class="sidebar-nav-item" href="https://www.youtube.com/channel/UCSv1_NZITsPl-abaCWtRrJg" target="_blank">YouTube</a>
      <a class="sidebar-nav-item" href="https://ml.utexas.edu/ifml" target="_blank">IFML</a>
      <a class="sidebar-nav-item" href="https://wncg.org" target="_blank">WNCG</a>
      <a class="sidebar-nav-item" href="https://www.utmlds.club/" target="_blank">MLDS</a>





      <!--<span class="sidebar-nav-item">Jekyll Hyde, Currently v2.1.0</span>-->
    </nav>

    <p>&copy; 2021. All rights reserved.</p> 
  </div>
</div>


    <div class="content container">
      <div class="page">
  <h1 class="page-title"></h1>
  <table class="imgtable"><tr><td>
<img src="images/Caramanis_ECE_2018_06.jpg" alt="Constantine Caramanis Photo" width="150px" />&nbsp;</td>
<td align="left"><ul>
<p style="font-family: 'Garamond';font-size:16px"><b>Constantine Caramanis</b></p>
<p style="font-family: 'Garamond';font-size:16px">Professor, Dept. of <a href="http://www.ece.utexas.edu/" target="_blank">Electrical 
and Computer Engineering</a></p>
<p style="font-family: 'Garamond';font-size:16px">Chandra Family Endowed Distinguished Professorship in Electrical and Computer Engineering</p>
<p style="font-family: 'Garamond';font-size:16px">Member of the <a href="http://www.cs.utexas.edu/" target="_blank">Computer Science</a> Graduate 
Studies Committee </p>
<p style="font-family: 'Garamond';font-size:16px">Office: 2501 Speedway, EER Building Room 6.820</p>
<p style="font-family: 'Garamond';font-size:16px"><tt>e-mail: constantine <a href="at">at</a> utexas.edu</tt></p>
 <br />
</ul>
</td></tr></table>

<hr />

<p>
I am a Professor in the ECE department of The University of Texas at Austin. I received a PhD in EECS from The Massachusetts Institute of Technology, in the Laboratory for Information and Decision Systems (LIDS), and an AB in Mathematics from Harvard University. I received the NSF CAREER award in 2011.
</p>
<p><br /></p>

<p>My current research interests focus on decision-making in large-scale complex systems, with a focus on learning and computation. Specifically, I am interested in robust and adaptable optimization, high dimensional statistics and machine learning, and applications to large-scale networks, including social networks, wireless networks, transportation networks, and energy networks. I have also worked on applications of machine learning and optimization to computer-aided design.
</p>
<p><br /></p>
<p> I am affiliated with the NSF <a href="https://ml.utexas.edu/ifml" target="_blank">Institute for Foundations of Machine Learning.</a></p>

<hr />

<h3 id="teaching">Teaching</h3>

<ul>
  <li>
    <p>Fall 2021: Convex Optimization</p>
  </li>
  <li>
    <p>Spring 2021: Data Science Lab</p>
  </li>
  <li>
    <p>Fall 2020: Combinatorial Optimization</p>
  </li>
  <li>
    <p>Spring 2020: Large Scale Optimization II</p>
  </li>
</ul>

<p>I have also created two classes which I have made available online.</p>

<ul>
  <li>
    <p><a href="https://www.youtube.com/playlist?list=PLXsmhnDvpjORzPelSDs0LSDrfJcqyLlZc" target="_blank"> Optimization Algorithms</a></p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/playlist?list=PLXsmhnDvpjORcTRFMVF3aUgyYlHsxfhNL" target="_blank">Combinatorial Optimization</a></p>
  </li>
</ul>

<hr />

<h3 id="research-group">Research Group</h3>

<h4 id="current-group">Current Group</h4>

<ul>
  <li>
    <p>Alexia Atsidakou (ECE) (co-advised with Sujay Sanghavi)</p>
  </li>
  <li>
    <p><a href="https://matthewfaw.github.io/" target="_blank">Matthew Faw (ECE)</a> (co-advised with Sanjay Shakkottai)</p>
  </li>
  <li>
    <p><a href="https://lntk.github.io//" target="_blank">Khang Le (ECE) </a> (co-advised with Nhat Ho)</p>
  </li>
  <li>
    <p><a href="https://kwonchungli.github.io/" target="_blank">Jeongyeol Kwon (ECE) </a></p>
  </li>
  <li>
    <p><a href="https://www.cs.utexas.edu/~papadig/" target="_blank">Orestis Papadigenopoulos (CS) </a></p>
  </li>
  <li>
    <p><a href="http://www.cs.utexas.edu/~jzhuo/" target="_blank">Jiacheng Zhuo (CS)</a></p>
  </li>
</ul>

<h4 id="group-alumni">Group Alumni</h4>

<ul>
  <li>
    <p><a href="https://www.linkedin.com/in/eirini-asteri-a015a9174/" target="_blank">Eirini Asteri</a> (co-advised with Alex Dimakis): Google</p>
  </li>
  <li>
    <p><a href="https://people.orie.cornell.edu/yudong.chen/" target="_blank">Yudong Chen</a>: Associate Professor at Cornell ORIE –&gt; Associate Professor at Wisconsin-Madison CS.</p>
  </li>
  <li>
    <p><a href="https://www.linkedin.com/in/douglasfearing" target="_blank">Doug Fearing</a> (with C. Barnhart, MIT): Assistant Professor, UT Austin B. School –&gt; Dodgers –&gt; Zelus Analytics</p>
  </li>
  <li>
    <p><a href="https://www.linkedin.com/in/aminkhalek/" target="_blank">Amin Abdel-Khalek</a> (co-advised with Robert Heath): Apple</p>
  </li>
  <li>
    <p><a href="https://www.linkedin.com/in/harish-ganapathy-0a940414/" target="_blank">Harish Ganapathy</a>: Google Brain</p>
  </li>
  <li>
    <p><a href="https://ece.iisc.ac.in/~aditya/" target="_blank">Aditya Gopalan</a> (with Sanjay Shakkottai): Associate Professor, Indian Institute of Science</p>
  </li>
  <li>
    <p><a href="https://www.linkedin.com/in/melissa-hall-924a44b6/" target="_blank">Melissa Hall</a>: Facebook</p>
  </li>
  <li>
    <p><a href="https://www.cs.utexas.edu/~hoffmann/" target="_blank">Jessica Hoffmann</a>: Google</p>
  </li>
  <li>
    <p><a href="https://www.linkedin.com/in/kiyeon-jeon/?originalSubdomain=kr" target="_blank">Kiyeon Jeon</a>: IBM</p>
  </li>
  <li>
    <p>Ken’ichi Kamada: Visiting Scientist from Yokogawa Co.</p>
  </li>
  <li>
    <p><a href="https://ashishkatiyar13.github.io/" target="_blank">Ashish Katiyar </a>: Amazon</p>
  </li>
  <li>
    <p><a href="http://akyrillidis.github.io/about/" target="_blank">Anastasios Kyrillidis</a> (w/ Sujay Sanghavi &amp; Alex Dimakis): Assistant Professor, Rice CS</p>
  </li>
  <li>
    <p><a href="http://li-tianyang.com/research/" target="_blank">Tianyang Li</a>: Two Sigma</p>
  </li>
  <li>
    <p><a href="https://liuliuforph.github.io/" target="_blank">Liu Liu</a>: Tencent</p>
  </li>
  <li>
    <p><a href="http://mitliagkas.github.io/" target="_blank">Ioannis Mitliagkas</a> (co-advised with Sriram Vishwanath): Assistant Professor, U. Montreal</p>
  </li>
  <li>
    <p><a href="https://web.ma.utexas.edu/users/jneeman/" target="_blank">Joe Neeman</a> (co-advised with Sujay Sanghavi): Assistant Professor, UT Austin, Math</p>
  </li>
  <li>
    <p><a href="http://dhpark22.github.io/" target="_blank"> Dohyung Park</a> (co-advised with Sujay Sanghavi): Facebook</p>
  </li>
  <li>
    <p><a href="https://sites.google.com/site/pslsri93/home" target="_blank">Srilakshmi Pattabiraman</a>: UIUC Ph.D.</p>
  </li>
  <li>
    <p><a href="https://www.linkedin.com/in/sanika-phanse-245429145/" target="_blank">Sanika Phanse</a>: MongoDB</p>
  </li>
  <li>
    <p><a href="https://www.linkedin.com/in/zrinka-puljiz-133a593" target="_blank">Zrinka Puljiz</a> (co-advised with Sanjay Shakkottai): Google</p>
  </li>
  <li>
    <p>Ashish Singh (with Michael Orshansky): Terra Technology</p>
  </li>
  <li>
    <p><a href="https://sites.gatech.edu/huan-xu/" target="_blank">Huan Xu</a> (with David Morton): Assistant Professor, Georgia Tech, ISyE Dept. –&gt; Alibaba</p>
  </li>
  <li>
    <p><a href="https://www.linkedin.com/in/ye-wang-301b8648" target="_blank">Wang Ye</a> (co-advised with Michael Orshansky): Cadence</p>
  </li>
  <li>
    <p><a href="https://www.linkedin.com/in/qiaoyang-ye-92073548" target="_blank">Qiaoyang Ye</a> (co-advised with Jeff Andrews): Samsung Research America</p>
  </li>
  <li>
    <p><a href="https://www.linkedin.com/in/xinyang-yi-21818845" target="_blank">Xinyang Yi</a>: Google</p>
  </li>
  <li>
    <p><a href="https://www.linkedin.com/in/sungho-yun-4821131a" target="_blank">Sungho Yun</a>: Apple.</p>
  </li>
</ul>

<hr />
<h3 id="the-last-ten-publications-chronologically">The last ten publications, chronologically…</h3>
<ol class="bibliography"><li><div class="text-justify"><span id="hoffmann2020quarantines">Hoffmann, Jessica, Matt Jordan, and Constantine Caramanis. “Quarantines as a Targeted Immunization Strategy.” <i>Preprint</i>, 2021.</span></div>
<button class="button0" onclick="toggleBibtexhoffmann2020quarantines()">Bibtex</button>
 

<button class="button0" onclick="toggleAbstracthoffmann2020quarantines()">Abstract</button>



    <a href="https://arxiv.org/pdf/2008.08262.pdf"><input class="button4" type="button" value="ArXiv" /></a>

 


<div id="Bhoffmann2020quarantines" style="display: none;">
<pre>@article{hoffmann2020quarantines,
  title = {Quarantines as a Targeted Immunization Strategy},
  author = {Hoffmann, Jessica and Jordan, Matt and Caramanis, Constantine},
  journal = {preprint},
  year = {2021},
  group = {misc},
  arxiv = {https://arxiv.org/pdf/2008.08262.pdf}
}
</pre>
</div>

<div id="ahoffmann2020quarantines" style="display: none;">
<pre>In the context of the recent COVID-19 outbreak, quarantine has been used to "flatten the curve" and slow the spread of the disease. In this paper, we show that this is not the only benefit of quarantine for the mitigation of an SIR epidemic spreading on a graph. Indeed, human contact networks exhibit a powerlaw structure, which means immunizing nodes at random is extremely ineffective at slowing the epidemic, while immunizing high-degree nodes can efficiently guarantee herd immunity. We theoretically prove that if quarantines are declared at the right moment, high-degree nodes are disproportionately in the Removed state, which is a form of targeted immunization. Even if quarantines are declared too early, subsequent waves of infection spread slower than the first waves. This leads us to propose an opening and closing strategy aiming at immunizing the graph while infecting the minimum number of individuals, guaranteeing the population is now robust to future infections. To the best of our knowledge, this is the only strategy that guarantees herd immunity without requiring vaccines. We extensively verify our results on simulated and real-life networks.</pre>
</div>


<script>
function toggleAbstractCChoffmann2020quarantines(parameter) {
    var x= document.getElementById('ahoffmann2020quarantines');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleBibtexhoffmann2020quarantines(parameter) {
    var x= document.getElementById('Bhoffmann2020quarantines');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleAbstracthoffmann2020quarantines(parameter) {
    var x= document.getElementById('ahoffmann2020quarantines');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>
</li>
<li><div class="text-justify"><span id="katiyarRobustMRF2021">Katiyar, Ashish, Soumya Basu, Vatsal Shah, and Constantine Caramanis. “Robust Estimation of Tree Structured Markov Random Fields.” <i>Preprint</i>, 2021.</span></div>
<button class="button0" onclick="toggleBibtexkatiyarRobustMRF2021()">Bibtex</button>
 

<button class="button0" onclick="toggleAbstractkatiyarRobustMRF2021()">Abstract</button>



    <a href="https://arxiv.org/pdf/2102.08554.pdf"><input class="button4" type="button" value="ArXiv" /></a>

 


<div id="BkatiyarRobustMRF2021" style="display: none;">
<pre>@article{katiyarRobustMRF2021,
  title = {Robust Estimation of Tree Structured Markov Random Fields},
  author = {Katiyar, Ashish and Basu, Soumya and Shah, Vatsal and Caramanis, Constantine},
  journal = {preprint},
  year = {2021},
  group = {misc},
  arxiv = {https://arxiv.org/pdf/2102.08554.pdf}
}
</pre>
</div>

<div id="akatiyarRobustMRF2021" style="display: none;">
<pre>We study the problem of learning tree-structured Markov random fields (MRF) on discrete random variables with common support when the observations are corrupted by unknown noise. As the presence of noise in the observations obfuscates the original tree structure, the extent of recoverability of the tree-structured MRFs under noisy observations is brought into question.
We show that in a general noise model, the underlying tree structure can be recovered only up to an equivalence class where each of the leaf nodes is indistinguishable from its parent and siblings, forming a leaf cluster. As the indistinguishability arises due to contrived noise models, we study the natural k-ary symmetric channel noise model where the value of each node is changed to a uniform value in the support with an unequal and unknown probability. Here, the answer becomes much more nuanced. We show that with a support size of 2, and the binary symmetric channel noise model, the leaf clusters remain indistinguishable. From support size 3 and up, the recoverability of a leaf cluster is dictated by the joint probability mass function of the nodes within it. We provide a precise characterization of recoverability by deriving a necessary and sufficient condition for the recoverability of a leaf cluster. We provide an algorithm that recovers the tree if this condition is satisfied, and recovers the tree up to the leaf clusters failing this condition.</pre>
</div>


<script>
function toggleAbstractCCkatiyarRobustMRF2021(parameter) {
    var x= document.getElementById('akatiyarRobustMRF2021');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleBibtexkatiyarRobustMRF2021(parameter) {
    var x= document.getElementById('BkatiyarRobustMRF2021');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleAbstractkatiyarRobustMRF2021(parameter) {
    var x= document.getElementById('akatiyarRobustMRF2021');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>
</li>
<li><div class="text-justify"><span id="zhuoSlowMatrix2021">Zhuo, Jiacheng, Jeongyeol Kwon, Nhat Ho, and Constantine Caramanis. “On the Computational and Statistical Complexity of over-Parameterized Matrix Sensing.” <i>Preprint</i>, 2021.</span></div>
<button class="button0" onclick="toggleBibtexzhuoSlowMatrix2021()">Bibtex</button>
 

<button class="button0" onclick="toggleAbstractzhuoSlowMatrix2021()">Abstract</button>



    <a href="https://arxiv.org/pdf/2102.02756.pdf"><input class="button4" type="button" value="ArXiv" /></a>

 


<div id="BzhuoSlowMatrix2021" style="display: none;">
<pre>@article{zhuoSlowMatrix2021,
  title = {On the computational and statistical complexity of over-parameterized matrix sensing},
  author = {Zhuo, Jiacheng and Kwon, Jeongyeol and Ho, Nhat and Caramanis, Constantine},
  journal = {preprint},
  year = {2021},
  group = {misc},
  arxiv = {https://arxiv.org/pdf/2102.02756.pdf}
}
</pre>
</div>

<div id="azhuoSlowMatrix2021" style="display: none;">
<pre>We consider solving the low rank matrix sensing problem with Factorized Gradient Descend (FGD) method when the true rank is unknown and over-specified, which we refer to as over-parameterized matrix sensing.
If the ground truth signal X^* ∈\mathbbR^d*d is of rank r, but we try to recover it using FF^⊤where F ∈\mathbbR^d*k and k&gt;r, the existing statistical analysis falls short, due to a flat local curvature of the loss function around the global maxima. By decomposing the factorized matrix \fitMat into separate column spaces to capture the effect of extra ranks, we show that ||F_t F_t - F||_F^2 converges to a statistical error of \tilde\mathcalO \parenthk d σ^2/n after \tilde\mathcalO(\frac\sigma_rσ\sqrt\fracnd) number of iterations where \fitMat_t is the output of FGD after t iterations, σ^2 is the variance of the observation noise, \sigma_r is the r-th largest eigenvalue of \trueMat, and n is the number of sample. Our results, therefore, offer a comprehensive picture of the statistical and computational complexity of FGD for the over-parameterized matrix sensing problem.</pre>
</div>


<script>
function toggleAbstractCCzhuoSlowMatrix2021(parameter) {
    var x= document.getElementById('azhuoSlowMatrix2021');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleBibtexzhuoSlowMatrix2021(parameter) {
    var x= document.getElementById('BzhuoSlowMatrix2021');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleAbstractzhuoSlowMatrix2021(parameter) {
    var x= document.getElementById('azhuoSlowMatrix2021');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>
</li>
<li><div class="text-justify"><span id="kwon2021rl">Kwon, Jeongyeol, Yonathan Effroni, Constantine Caramanis, and Shie Mannor. “RL for Latent MDPs: Regret Guarantees and a Lower Bound.” <i>Advances in Neural Information Processing Systems (NeurIPS)</i>, 2021.</span></div>
<button class="button0" onclick="toggleBibtexkwon2021rl()">Bibtex</button>
 

<button class="button0" onclick="toggleAbstractkwon2021rl()">Abstract</button>



    <a href="https://arxiv.org/pdf/2102.00321.pdf"><input class="button4" type="button" value="ArXiv" /></a>

 


<div id="Bkwon2021rl" style="display: none;">
<pre>@article{kwon2021rl,
  title = {RL for Latent MDPs: Regret Guarantees and a Lower Bound},
  author = {Kwon, Jeongyeol and Effroni, Yonathan and Caramanis, Constantine and Mannor, Shie},
  journal = {Advances in Neural Information Processing Systems (NeurIPS)},
  year = {2021},
  group = {proceedings},
  arxiv = {https://arxiv.org/pdf/2102.00321.pdf}
}
</pre>
</div>

<div id="akwon2021rl" style="display: none;">
<pre>In this work, we consider the regret minimization problem for reinforcement learning in latent Markov Decision Processes (LMDP). In an LMDP, an MDP is randomly drawn from a set of M possible MDPs at the beginning of the interaction, but the identity of the chosen MDP is not revealed to the agent. We first show that a general instance of LMDPs requires at least Ω((SA)M) episodes to even approximate the optimal policy. Then, we consider sufficient assumptions under which learning good policies requires polynomial number of episodes. We show that the key link is a notion of separation between the MDP system dynamics. With sufficient separation, we provide an efficient algorithm with local guarantee, \it i.e., providing a sublinear regret guarantee when we are given a good initialization. Finally, if we are given standard statistical sufficiency assumptions common in the Predictive State Representation (PSR) literature (e.g., Boots et al.) and a reachability assumption, we show that the need for initialization can be removed.</pre>
</div>


<script>
function toggleAbstractCCkwon2021rl(parameter) {
    var x= document.getElementById('akwon2021rl');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleBibtexkwon2021rl(parameter) {
    var x= document.getElementById('Bkwon2021rl');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleAbstractkwon2021rl(parameter) {
    var x= document.getElementById('akwon2021rl');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>
</li>
<li><div class="text-justify"><span id="kwon2021rlb">———. “Reinforcement Learning in Reward-Mixing MDPs.” <i>Advances in Neural Information Processing Systems (NeurIPS)</i>, 2021.</span></div>
<button class="button0" onclick="toggleBibtexkwon2021rlb()">Bibtex</button>
 

<button class="button0" onclick="toggleAbstractkwon2021rlb()">Abstract</button>



    <a href=""><input class="button4" type="button" value="ArXiv" /></a>

 


<div id="Bkwon2021rlb" style="display: none;">
<pre>@article{kwon2021rlb,
  title = {Reinforcement Learning in Reward-Mixing MDPs},
  author = {Kwon, Jeongyeol and Effroni, Yonathan and Caramanis, Constantine and Mannor, Shie},
  journal = {Advances in Neural Information Processing Systems (NeurIPS)},
  year = {2021},
  group = {proceedings},
  arxiv = {}
}
</pre>
</div>

<div id="akwon2021rlb" style="display: none;">
<pre>ILearning a near optimal policy in a partially observable system remains an elusive challenge in contemporary reinforcement learning. In this work, we consider episodic reinforcement learning in a reward-mixing Markov decision process (MDP). There, a reward function is drawn from one of multiple possible reward models at the beginning of every episode, but the identity of the chosen reward model is not revealed to the agent. Hence, the latent state space, for which the dynamics are Markovian, is not given to the agent. We study the problem of learning a near optimal policy for two reward-mixing MDPs. Unlike existing approaches that rely on strong assumptions on the dynamics, we make no assumptions and study the problem in full generality. Indeed, with no further assumptions, even for two switching reward-models, the problem requires several new ideas beyond existing algorithmic and analysis techniques for efficient exploration. We provide the first polynomial-time algorithm that finds an ε-optimal policy after exploring \tildeO(poly(H,ε^-1) ⋅S^2 A^2) episodes, where H is time-horizon and S, A are the number of states and actions respectively. This is the first efficient algorithm that does not require any assumptions in partially observed environments where the observation space is smaller than the latent state space.</pre>
</div>


<script>
function toggleAbstractCCkwon2021rlb(parameter) {
    var x= document.getElementById('akwon2021rlb');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleBibtexkwon2021rlb(parameter) {
    var x= document.getElementById('Bkwon2021rlb');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleAbstractkwon2021rlb(parameter) {
    var x= document.getElementById('akwon2021rlb');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>
</li>
<li><div class="text-justify"><span id="papadig2021recurrent">Papadigenopoulos, Orestis, and Constantine Caramanis. “Recurrent Submodular Welfare and Matroid Blocking Bandits.” <i>Advances in Neural Information Processing Systems (NeurIPS)</i>, 2021.</span></div>
<button class="button0" onclick="toggleBibtexpapadig2021recurrent()">Bibtex</button>
 

<button class="button0" onclick="toggleAbstractpapadig2021recurrent()">Abstract</button>



    <a href="https://arxiv.org/pdf/2102.00321.pdf"><input class="button4" type="button" value="ArXiv" /></a>

 


<div id="Bpapadig2021recurrent" style="display: none;">
<pre>@article{papadig2021recurrent,
  title = {Recurrent Submodular Welfare and Matroid Blocking Bandits},
  author = {Papadigenopoulos, Orestis and Caramanis, Constantine},
  journal = {Advances in Neural Information Processing Systems (NeurIPS)},
  year = {2021},
  group = {proceedings},
  arxiv = {https://arxiv.org/pdf/2102.00321.pdf}
}
</pre>
</div>

<div id="apapadig2021recurrent" style="display: none;">
<pre>A recent line of research focuses on the study of the stochastic multi-armed bandits problem (MAB), in the case where temporal correlations of specific structure are imposed between the player’s actions and the reward distributions of the arms (Kleinberg and Immorlica [FOCS18], Basu et al. [NIPS19]). As opposed to the standard MAB setting, where the optimal solution in hindsight can be trivially characterized, these correlations lead to (sub-)optimal solutions that exhibit interesting dynamical patterns – a phenomenon that yields new challenges both from an algorithmic as well as a learning perspective. In this work, we extend the above direction to a combinatorial bandit setting and study a variant of stochastic MAB, where arms are subject to matroid constraints and each arm becomes unavailable (blocked) for a fixed number of rounds after each play. A natural common generalization of the state-of-the-art for blocking bandits, and that for matroid bandits, yields a (1−1/e)-approximation for partition matroids, yet it only guarantees a 1/2-approximation for general matroids. In this paper we develop new algorithmic ideas that allow us to obtain a polynomial-time (1−1/e)-approximation algorithm (asymptotically and in expectation) for any matroid, and thus allow us to control the (1−1/e)-approximate regret. A key ingredient is the technique of correlated (interleaved) scheduling. Along the way, we discover an interesting connection to a variant of Submodular Welfare Maximization, for which we provide (asymptotically) matching upper and lower approximability bounds.</pre>
</div>


<script>
function toggleAbstractCCpapadig2021recurrent(parameter) {
    var x= document.getElementById('apapadig2021recurrent');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleBibtexpapadig2021recurrent(parameter) {
    var x= document.getElementById('Bpapadig2021recurrent');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleAbstractpapadig2021recurrent(parameter) {
    var x= document.getElementById('apapadig2021recurrent');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>
</li>
<li><div class="text-justify"><span id="kwon2020minimax">Kwon, Jeongyeol, Nhat Ho, and Constantine Caramanis. “On the Minimax Optimality of the Em Algorithm for Learning Two-Component Mixed Linear Regression.” In <i>International Conference on Artificial Intelligence and Statistics (AISTATS)</i>. PMLR, 2021.</span></div>
<button class="button0" onclick="toggleBibtexkwon2020minimax()">Bibtex</button>
 

<button class="button0" onclick="toggleAbstractkwon2020minimax()">Abstract</button>



    <a href="https://arxiv.org/pdf/2006.02601.pdf"><input class="button4" type="button" value="ArXiv" /></a>

 


<div id="Bkwon2020minimax" style="display: none;">
<pre>@inproceedings{kwon2020minimax,
  title = {On the minimax optimality of the em algorithm for learning two-component mixed linear regression},
  author = {Kwon, Jeongyeol and Ho, Nhat and Caramanis, Constantine},
  booktitle = {International Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages = {},
  year = {2021},
  organization = {PMLR},
  group = {proceedings},
  arxiv = {https://arxiv.org/pdf/2006.02601.pdf}
}
</pre>
</div>

<div id="akwon2020minimax" style="display: none;">
<pre>We study the convergence rates of the EM algorithm for learning two-component mixed linear regression under all regimes of signal-to-noise ratio (SNR). We resolve a long-standing question that many recent results have attempted to tackle: we completely characterize the convergence behavior of EM, and show that the EM algorithm achieves minimax optimal sample complexity under all SNR regimes. In particular, when the SNR is sufficiently large, the EM updates converge to the true parameter θ^* at the standard parametric convergence rate \calo((d/n)^1/2) after \calo(\log(n/d)) iterations. In the regime where the SNR is above \calo((d/n)^1/4) and below some constant, the EM iterates converge to a \calo(\rm SNR^-1 (d/n)^1/2) neighborhood of the true parameter, when the number of iterations is of the order \calo(\rm SNR^-2 \log(n/d)). In the low SNR regime where the SNR is below \calo((d/n)^1/4), we show that EM converges to a \calo((d/n)^1/4) neighborhood of the true parameters, after \calo((n/d)^1/2) iterations. Notably, these results are achieved under mild conditions of either random initialization or an efficiently computable local initialization. By providing tight convergence guarantees of the EM algorithm in middle-to-low SNR regimes, we fill the remaining gap in the literature, and significantly, reveal that in low SNR, EM changes rate, matching the n^-1/4 rate of the MLE, a behavior that previous work had been unable to show. </pre>
</div>


<script>
function toggleAbstractCCkwon2020minimax(parameter) {
    var x= document.getElementById('akwon2020minimax');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleBibtexkwon2020minimax(parameter) {
    var x= document.getElementById('Bkwon2020minimax');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleAbstractkwon2020minimax(parameter) {
    var x= document.getElementById('akwon2020minimax');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>
</li>
<li><div class="text-justify"><span id="basu2020contextual">Basu, Soumya, Orestis Papadigenopoulos, Constantine Caramanis, and Sanjay Shakkottai. “Contextual Blocking Bandits.” In <i>International Conference on Artificial Intelligence and Statistics (AISTATS)</i>. PMLR, 2021.</span></div>
<button class="button0" onclick="toggleBibtexbasu2020contextual()">Bibtex</button>
 

<button class="button0" onclick="toggleAbstractbasu2020contextual()">Abstract</button>



    <a href="https://arxiv.org/pdf/2003.03426.pdf"><input class="button4" type="button" value="ArXiv" /></a>

 


<div id="Bbasu2020contextual" style="display: none;">
<pre>@inproceedings{basu2020contextual,
  title = {Contextual Blocking Bandits},
  author = {Basu, Soumya and Papadigenopoulos, Orestis and Caramanis, Constantine and Shakkottai, Sanjay},
  booktitle = {International Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages = {},
  year = {2021},
  organization = {PMLR},
  group = {proceedings},
  arxiv = {https://arxiv.org/pdf/2003.03426.pdf}
}
</pre>
</div>

<div id="abasu2020contextual" style="display: none;">
<pre>We study a novel variant of the multi-armed bandit problem, where at each time step, the player observes an independently sampled context that determines the arms’ mean rewards. However, playing an arm blocks it (across all contexts) for a fixed number of future time steps. The above contextual setting captures important scenarios such as recommendation systems or ad placement with diverse users.
This problem has been recently studied \citepDSSX18 in the full-information setting (i.e., assuming knowledge of the mean context-dependent arm rewards), where competitive ratio bounds have been derived.
We focus on the bandit setting, where these means are initially unknown; we propose a UCB-based variant of the full-information algorithm that guarantees a \mathcalO(\log T)-regret w.r.t. an α-optimal strategy in T time steps, matching the Ω(\log(T)) regret lower bound in this setting. Due to the time correlations caused by blocking, existing techniques for upper bounding regret fail. For proving our regret bounds, we introduce the novel concepts of delayed exploitation and opportunistic sub-sampling and combine them with ideas from combinatorial bandits and non-stationary Markov chains coupling.</pre>
</div>


<script>
function toggleAbstractCCbasu2020contextual(parameter) {
    var x= document.getElementById('abasu2020contextual');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleBibtexbasu2020contextual(parameter) {
    var x= document.getElementById('Bbasu2020contextual');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleAbstractbasu2020contextual(parameter) {
    var x= document.getElementById('abasu2020contextual');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>
</li>
<li><div class="text-justify"><span id="atsidakou2021combinatorial">Atsidakou, Alexia, Orestis Papadigenopoulos, Soumya Basu, Constantine Caramanis, and Sanjay Shakkottai. “Combinatorial Blocking Bandits with Stochastic Delays.” In <i>International Conference on Machine Learning (ICML)</i>. PMLR, 2021.</span></div>
<button class="button0" onclick="toggleBibtexatsidakou2021combinatorial()">Bibtex</button>
 

<button class="button0" onclick="toggleAbstractatsidakou2021combinatorial()">Abstract</button>



    <a href="https://arxiv.org/pdf/2105.10625.pdf"><input class="button4" type="button" value="ArXiv" /></a>

 


<div id="Batsidakou2021combinatorial" style="display: none;">
<pre>@inproceedings{atsidakou2021combinatorial,
  title = {Combinatorial Blocking Bandits with Stochastic Delays},
  author = {Atsidakou, Alexia and Papadigenopoulos, Orestis and Basu, Soumya and Caramanis, Constantine and Shakkottai, Sanjay},
  booktitle = {International Conference on Machine Learning (ICML)},
  year = {2021},
  organization = {PMLR},
  group = {proceedings},
  arxiv = {https://arxiv.org/pdf/2105.10625.pdf}
}
</pre>
</div>

<div id="aatsidakou2021combinatorial" style="display: none;">
<pre>Recent work has considered natural variations of the \em multi-armed bandit problem, where the reward distribution of each arm is a special function of the time passed since its last pulling. In this direction, a simple (yet widely applicable) model is that of \em blocking bandits, where an arm becomes unavailable for a deterministic number of rounds after each play. In this work, we extend the above model in two directions: (i) We consider the general combinatorial setting where more than one arms can be played at each round, subject to feasibility constraints. (ii) We allow the blocking time of each arm to be stochastic. We first study the computational/unconditional hardness of the above setting and identify the necessary conditions for the problem to become tractable (even in an approximate sense). Based on these conditions, we provide a tight analysis of the approximation guarantee of a natural greedy heuristic that always plays the maximum expected reward feasible subset among the available (non-blocked) arms. When the arms’ expected rewards are unknown, we adapt the above heuristic into a bandit algorithm, based on UCB, for which we provide sublinear (approximate) regret guarantees, matching the theoretical lower bounds in the limiting case of absence of delays.</pre>
</div>


<script>
function toggleAbstractCCatsidakou2021combinatorial(parameter) {
    var x= document.getElementById('aatsidakou2021combinatorial');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleBibtexatsidakou2021combinatorial(parameter) {
    var x= document.getElementById('Batsidakou2021combinatorial');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleAbstractatsidakou2021combinatorial(parameter) {
    var x= document.getElementById('aatsidakou2021combinatorial');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>
</li>
<li><div class="text-justify"><span id="caramanis2021single">Caramanis, Constantine, Paul Duetting, Matthew Faw, Federico Fusco, Philip Lazo, Stefano Leonardi, Orestis Papadigenopoulos, Emmanouil Pountourakis, and Rebecca Reiffenhauser. “Single Sample Prophet Inequalities via Greedy-Ordered Selection.” <i>Symposium on Discrete Algorithms (SODA)</i>, 2021.</span></div>
<button class="button0" onclick="toggleBibtexcaramanis2021single()">Bibtex</button>
 

<button class="button0" onclick="toggleAbstractcaramanis2021single()">Abstract</button>



    <a href="https://arxiv.org/pdf/2103.13089.pdf"><input class="button4" type="button" value="ArXiv" /></a>

 


<div id="Bcaramanis2021single" style="display: none;">
<pre>@article{caramanis2021single,
  title = {Single Sample Prophet Inequalities via Greedy-Ordered Selection},
  author = {Caramanis, Constantine and Duetting, Paul and Faw, Matthew and Fusco, Federico and Lazo, Philip and Leonardi, Stefano and Papadigenopoulos, Orestis and Pountourakis, Emmanouil and Reiffenhauser, Rebecca},
  booktitle = {Symposium on Discrete Algorithms (SODA)},
  year = {2021},
  group = {proceedings},
  arxiv = {https://arxiv.org/pdf/2103.13089.pdf}
}
</pre>
</div>

<div id="acaramanis2021single" style="display: none;">
<pre>We study <i>Single-Sample Prophet Inequalities</i> (SSPIs), i.e.,  prophet inequalities where only a single sample from each prior distribution is available. Besides a direct, and optimal, SSPI for the basic single choice problem [Rubinstein et al., ITCS’20], most existing SSPI results were obtained via an elegant, but inherently lossy reduction to Order Oblivious Secretary (OOS) policies [Azar et al., SODA’14]. Motivated by this discrepancy, we develop an intuitive and versatile greedy-based technique that yields SSPIs <i>directly</i> rather than through the reduction to OOS. Our results can be seen as generalizing and unifying a number of existing results in the area of prophet and secretary problems. Our algorithms significantly improve on the competitive guarantees for a number of interesting scenarios (including general matching with edge arrivals, bipartite matching with vertex arrivals and certain matroids), as well as capture new settings (e.g., budget additive valuations). Complementing our algorithmic results, we also consider mechanism design variants. Finally, we analyze the power and limitations of different SSPI approaches by providing a partial converse to the reduction from SSPI to OOS given by [Azar et al., SODA’14].  </pre>
</div>


<script>
function toggleAbstractCCcaramanis2021single(parameter) {
    var x= document.getElementById('acaramanis2021single');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleBibtexcaramanis2021single(parameter) {
    var x= document.getElementById('Bcaramanis2021single');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleAbstractcaramanis2021single(parameter) {
    var x= document.getElementById('acaramanis2021single');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>
</li></ol>


</div>

    </div>
    
  </body>
</html>
