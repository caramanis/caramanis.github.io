<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
       &middot; Constantine Caramanis
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body>

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h2>
        Constantine Caramanis
      </h2>
      <p class="lead"></p>
    </div>

    <nav class="sidebar-nav">


      

      <a class="sidebar-nav-item active" href="/">Home</a>
      <a class="sidebar-nav-item" href="/teaching/">Teaching</a>
      <a class="sidebar-nav-item" href="/publications/">Publications</a>
      <a class="sidebar-nav-item" href="/researchgroup/">Research Group</a>
      <a class="sidebar-nav-item" href="/researchprojects/">Research Projects</a>
      <a class="sidebar-nav-item" href="https://scholar.google.com/citations?user=47YTUrEAAAAJ&hl=en&oi=ao" target="_blank">Google Scholar</a>
      <a class="sidebar-nav-item" href="https://www.youtube.com/channel/UCSv1_NZITsPl-abaCWtRrJg" target="_blank">YouTube</a>
      <a class="sidebar-nav-item" href="https://ml.utexas.edu/ifml" target="_blank">IFML</a>
      <a class="sidebar-nav-item" href="https://wncg.org" target="_blank">WNCG</a>
      <a class="sidebar-nav-item" href="https://www.utmlds.club/" target="_blank">MLDS</a>





      <!--<span class="sidebar-nav-item">Jekyll Hyde, Currently v2.1.0</span>-->
    </nav>

    <p>&copy; 2023. All rights reserved.</p> 
  </div>
</div>


    <div class="content container">
      <div class="page">
  <h1 class="page-title"></h1>
  <table class="imgtable"><tr><td>
<img src="images/Caramanis_ECE_2018_06.jpg" alt="Constantine Caramanis Photo" width="150px" />&nbsp;</td>
<td align="left"><ul>
<p style="font-family: 'Garamond';font-size:16px"><b>Constantine Caramanis</b></p>
<p style="font-family: 'Garamond';font-size:16px">Professor, Dept. of <a href="http://www.ece.utexas.edu/" target="_blank">Electrical 
and Computer Engineering</a></p>
<p style="font-family: 'Garamond';font-size:16px">Chandra Family Endowed Distinguished Professorship in Electrical and Computer Engineering</p>
<p style="font-family: 'Garamond';font-size:16px">Member of the <a href="http://www.cs.utexas.edu/" target="_blank">Computer Science</a> Graduate 
Studies Committee </p>
<p style="font-family: 'Garamond';font-size:16px">Office: 2501 Speedway, EER Building Room 6.820</p>
<p style="font-family: 'Garamond';font-size:16px"><tt>e-mail: constantine <a href="at">at</a> utexas.edu</tt></p>
 <br />
</ul>
</td></tr></table>

<hr />

<p>
I am a Professor in the ECE department of The University of Texas at Austin. I received a PhD in EECS from The Massachusetts Institute of Technology, in the Laboratory for Information and Decision Systems (LIDS), and an AB in Mathematics from Harvard University. I received the NSF CAREER award in 2011, and I am an IEEE Fellow. 
</p>
<p><br /></p>

<p>My current research interests focus on decision-making in large-scale complex systems, with a focus on learning and computation. Specifically, I am interested in robust and adaptable optimization, high dimensional statistics and machine learning, and applications to large-scale networks, including social networks, wireless networks, transportation networks, and energy networks. I have also worked on applications of machine learning and optimization to computer-aided design.
</p>
<p><br /></p>
<p> I am affiliated with the NSF <a href="https://ml.utexas.edu/ifml" target="_blank">Institute for Foundations of Machine Learning,</a> and the <a href="https://ml.utexas.edu/" target="_blank"> Machine Learning Lab.</a></p>
<p> I am affiliated with the <a href="https://www.athenarc.gr/en/archimedes" target="_blank">Archimedes Research Center</a> in Athens.</p>

<hr />

<h3 id="teaching">Teaching</h3>

<ul>
  <li>Fall 2023: Convex Optimization</li>
  <li>
    <p>Fall 2022 / Spring 2023: On leave.</p>
  </li>
  <li>
    <p>Spring 2022: Data Science Lab</p>
  </li>
  <li>
    <p>Fall 2021: Convex Optimization</p>
  </li>
  <li>
    <p>Fall 2020: Combinatorial Optimization</p>
  </li>
  <li>Spring 2020: Large Scale Optimization II</li>
</ul>

<p>I have also created two classes which I have made available online.</p>

<ul>
  <li>
    <p><a href="https://www.youtube.com/playlist?list=PLXsmhnDvpjORzPelSDs0LSDrfJcqyLlZc" target="_blank"> Optimization Algorithms</a></p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/playlist?list=PLXsmhnDvpjORcTRFMVF3aUgyYlHsxfhNL" target="_blank">Combinatorial Optimization</a></p>
  </li>
</ul>

<hr />

<h3 id="research-group">Research Group</h3>

<h4 id="current-group">Current Group</h4>

<ul>
  <li>
    <p><a href="https://alexia-atsidakou.netlify.app/" target="_blank">Alexia Atsidakou (ECE)</a> (co-advised with Sujay Sanghavi)</p>
  </li>
  <li>
    <p><a href="https://matthewfaw.github.io/" target="_blank">Matthew Faw (ECE)</a> (co-advised with Sanjay Shakkottai)</p>
  </li>
  <li>
    <p><a href="https://lntk.github.io//" target="_blank">Khang Le (ECE) </a> (co-advised with Nhat Ho)</p>
  </li>
  <li>
    <p><a href="https://liturout.github.io/" target="_blank">Litu Rout (ECE) </a> (co-advised with Sanjay Shakkottai)</p>
  </li>
</ul>

<h4 id="group-alumni">Group Alumni</h4>

<ul>
  <li>
    <p><a href="https://www.linkedin.com/in/eirini-asteri-a015a9174/" target="_blank">Eirini Asteri</a> (co-advised with Alex Dimakis): Google</p>
  </li>
  <li>
    <p><a href="https://people.orie.cornell.edu/yudong.chen/" target="_blank">Yudong Chen</a>: Associate Professor at Cornell ORIE –&gt; Associate Professor at Wisconsin-Madison CS.</p>
  </li>
  <li>
    <p><a href="https://www.linkedin.com/in/douglasfearing" target="_blank">Doug Fearing</a> (with C. Barnhart, MIT): Assistant Professor, UT Austin B. School –&gt; Dodgers –&gt; Zelus Analytics</p>
  </li>
  <li>
    <p><a href="https://www.linkedin.com/in/aminkhalek/" target="_blank">Amin Abdel-Khalek</a> (co-advised with Robert Heath): Apple</p>
  </li>
  <li>
    <p><a href="https://www.linkedin.com/in/harish-ganapathy-0a940414/" target="_blank">Harish Ganapathy</a>: Google Brain</p>
  </li>
  <li>
    <p><a href="https://ece.iisc.ac.in/~aditya/" target="_blank">Aditya Gopalan</a> (with Sanjay Shakkottai): Associate Professor, Indian Institute of Science</p>
  </li>
  <li>
    <p><a href="https://www.linkedin.com/in/melissa-hall-924a44b6/" target="_blank">Melissa Hall</a>: Facebook</p>
  </li>
  <li>
    <p><a href="https://www.cs.utexas.edu/~hoffmann/" target="_blank">Jessica Hoffmann</a>: Google</p>
  </li>
  <li>
    <p><a href="https://www.linkedin.com/in/kiyeon-jeon/?originalSubdomain=kr" target="_blank">Kiyeon Jeon</a>: IBM</p>
  </li>
  <li>
    <p>Ken’ichi Kamada: Visiting Scientist from Yokogawa Co.</p>
  </li>
  <li>
    <p><a href="https://ashishkatiyar13.github.io/" target="_blank">Ashish Katiyar </a>: Amazon</p>
  </li>
  <li>
    <p><a href="https://kwonchungli.github.io/" target="_blank">Jeongyeol Kwon (ECE) </a>: Post doc at Madison</p>
  </li>
  <li>
    <p><a href="http://akyrillidis.github.io/about/" target="_blank">Anastasios Kyrillidis</a> (w/ Sujay Sanghavi &amp; Alex Dimakis): Assistant Professor, Rice CS</p>
  </li>
  <li>
    <p><a href="http://li-tianyang.com/research/" target="_blank">Tianyang Li</a>: Two Sigma</p>
  </li>
  <li>
    <p><a href="https://liuliuforph.github.io/" target="_blank">Liu Liu</a>: Tencent</p>
  </li>
  <li>
    <p><a href="http://mitliagkas.github.io/" target="_blank">Ioannis Mitliagkas</a> (co-advised with Sriram Vishwanath): Associate Professor, U. Montreal</p>
  </li>
  <li>
    <p><a href="https://web.ma.utexas.edu/users/jneeman/" target="_blank">Joe Neeman</a> (co-advised with Sujay Sanghavi): Assistant Professor, UT Austin, Math</p>
  </li>
  <li>
    <p><a href="http://dhpark22.github.io/" target="_blank"> Dohyung Park</a> (co-advised with Sujay Sanghavi): Facebook</p>
  </li>
  <li>
    <p><a href="http://www.columbia.edu/~vp2499/" target="_blank">Orestis Papadigenopoulos (CS) </a>: Post doc at Columbia’s Data Science Institute</p>
  </li>
  <li>
    <p><a href="https://sites.google.com/site/pslsri93/home" target="_blank">Srilakshmi Pattabiraman</a>: UIUC Ph.D.</p>
  </li>
  <li>
    <p><a href="https://www.linkedin.com/in/sanika-phanse-245429145/" target="_blank">Sanika Phanse</a>: MongoDB</p>
  </li>
  <li>
    <p><a href="https://www.linkedin.com/in/zrinka-puljiz-133a593" target="_blank">Zrinka Puljiz</a> (co-advised with Sanjay Shakkottai): Google</p>
  </li>
  <li>
    <p>Ashish Singh (with Michael Orshansky): Terra Technology</p>
  </li>
  <li>
    <p><a href="https://sites.gatech.edu/huan-xu/" target="_blank">Huan Xu</a> (with David Morton): Assistant Professor, Georgia Tech, ISyE Dept. –&gt; Alibaba</p>
  </li>
  <li>
    <p><a href="https://www.linkedin.com/in/ye-wang-301b8648" target="_blank">Wang Ye</a> (co-advised with Michael Orshansky): Cadence</p>
  </li>
  <li>
    <p><a href="https://www.linkedin.com/in/qiaoyang-ye-92073548" target="_blank">Qiaoyang Ye</a> (co-advised with Jeff Andrews): Samsung Research America</p>
  </li>
  <li>
    <p><a href="https://www.linkedin.com/in/xinyang-yi-21818845" target="_blank">Xinyang Yi</a>: Google Brain</p>
  </li>
  <li>
    <p><a href="https://www.linkedin.com/in/sungho-yun-4821131a" target="_blank">Sungho Yun</a>: Apple.</p>
  </li>
  <li>
    <p><a href="http://www.cs.utexas.edu/~jzhuo/" target="_blank">Jiacheng Zhuo</a>: Algorithm Developer at Hudson River Trading.</p>
  </li>
</ul>

<hr />
<h3 id="the-last-ten-publications-chronologically">The last ten publications, chronologically…</h3>
<ol class="bibliography"><li><div class="text-justify"><span id="rout23theoretical">Rout, Litu, Advait Parulekar, Constantine Caramanis, and Sanjay Shakkottai. “A Theoretical Justification for Image Inpainting Using Denoising Diffusion Probabilistic Models.” <i>Preprint</i>, 2023.</span></div>
<button class="button0" onclick="toggleBibtexrout23theoretical()">Bibtex</button>
 

<button class="button0" onclick="toggleAbstractrout23theoretical()">Abstract</button>



    <a href="https://arxiv.org/pdf/2302.01217.pdf"><input class="button4" type="button" value="ArXiv" /></a>

 


<div id="Brout23theoretical" style="display: none;">
<pre>@article{rout23theoretical,
  title = {A Theoretical Justification for Image Inpainting using Denoising Diffusion Probabilistic Models},
  author = {Rout, Litu and Parulekar, Advait and Caramanis, Constantine and Shakkottai, Sanjay},
  journal = {preprint},
  year = {2023},
  group = {misc},
  arxiv = {https://arxiv.org/pdf/2302.01217.pdf}
}
</pre>
</div>

<div id="arout23theoretical" style="display: none;">
<pre>We provide a theoretical justification for sample recovery using diffusion based image inpainting in a linear model setting. While most inpainting algorithms require retraining with each new mask, we prove that diffusion based inpainting generalizes well to unseen masks without retraining. We analyze a recently proposed popular diffusion based inpainting algorithm called RePaint, and show that it has a bias due to misalignment that hampers sample recovery even in a two-state diffusion process. Motivated by our analysis, we propose a modified RePaint algorithm we call RePaint^+ that provably recovers the underlying true sample and enjoys a linear rate of convergence. It achieves this by rectifying the misalignment error present in drift and dispersion of the reverse process. To the best of our knowledge, this is the first linear convergence result for a diffusion based image inpainting algorithm.</pre>
</div>


<script>
function toggleAbstractCCrout23theoretical(parameter) {
    var x= document.getElementById('arout23theoretical');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleBibtexrout23theoretical(parameter) {
    var x= document.getElementById('Brout23theoretical');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleAbstractrout23theoretical(parameter) {
    var x= document.getElementById('arout23theoretical');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>
</li>
<li><div class="text-justify"><span id="atsidakou23pandora">Atsidakou, Alexia, Constantine Caramanis, Evangelia Gergatsouli, Orestis Papadigenopoulos, and Christos Tzamos. “Contextual Pandora’s Box.” <i>Preprint</i>, 2023.</span></div>
<button class="button0" onclick="toggleBibtexatsidakou23pandora()">Bibtex</button>
 

<button class="button0" onclick="toggleAbstractatsidakou23pandora()">Abstract</button>



    <a href="https://arxiv.org/pdf/2205.13114.pdf"><input class="button4" type="button" value="ArXiv" /></a>

 


<div id="Batsidakou23pandora" style="display: none;">
<pre>@article{atsidakou23pandora,
  title = {Contextual Pandora's Box},
  author = {Atsidakou, Alexia and Caramanis, Constantine and Gergatsouli, Evangelia and Papadigenopoulos, Orestis and Tzamos, Christos},
  journal = {preprint},
  year = {2023},
  group = {misc},
  arxiv = {https://arxiv.org/pdf/2205.13114.pdf}
}
</pre>
</div>

<div id="aatsidakou23pandora" style="display: none;">
<pre>Pandora’s Box is a fundamental stochastic optimization problem, where the decision-maker must find a good alternative while minimizing the search cost of exploring the value of each alternative. In the original formulation, it is assumed that accurate priors are given for the values of all the alternatives, while
recent work studies the online variant of Pandora’s Box where priors are originally unknown. 
In this work, we extend Pandora’s Box to the online setting, while incorporating context. 
At every round, we are presented with a number of alternatives each having a context, an exploration cost and an unknown value drawn from an unknown prior distribution that may change at every round. Our main result is a no-regret algorithm that performs comparably well to the optimal algorithm which knows all prior distributions exactly. Our algorithm works even in the bandit setting where the algorithm never learns the values of the alternatives that were not explored. 
The key technique that enables our result is novel a modification of the realizability condition in contextual bandits that connects a context to the reservation value of the corresponding distribution rather than its mean.</pre>
</div>


<script>
function toggleAbstractCCatsidakou23pandora(parameter) {
    var x= document.getElementById('aatsidakou23pandora');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleBibtexatsidakou23pandora(parameter) {
    var x= document.getElementById('Batsidakou23pandora');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleAbstractatsidakou23pandora(parameter) {
    var x= document.getElementById('aatsidakou23pandora');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>
</li>
<li><div class="text-justify"><span id="faw23beyond">Faw, Matthew, Litu Rout, Constantine Caramanis, and Sanjay Shakkottai. “Beyond Uniform Smoothness: A Stopped Analysis of Adaptive SGD.” <i>Conference on Learning Theory (COLT)</i>, 2023.</span></div>
<button class="button0" onclick="toggleBibtexfaw23beyond()">Bibtex</button>
 

<button class="button0" onclick="toggleAbstractfaw23beyond()">Abstract</button>



    <a href="https://arxiv.org/pdf/2302.06570.pdf"><input class="button4" type="button" value="ArXiv" /></a>

 


<div id="Bfaw23beyond" style="display: none;">
<pre>@article{faw23beyond,
  title = {Beyond Uniform Smoothness: A Stopped Analysis of Adaptive SGD},
  author = {Faw, Matthew and Rout, Litu and Caramanis, Constantine and Shakkottai, Sanjay},
  journal = {Conference on Learning Theory (COLT)},
  year = {2023},
  group = {proceedings},
  arxiv = {https://arxiv.org/pdf/2302.06570.pdf}
}
</pre>
</div>

<div id="afaw23beyond" style="display: none;">
<pre>This work considers the problem of finding a first-order stationary point of a non-convex function with potentially unbounded smoothness constant using a stochastic gradient oracle. We focus on the class of (L_0,L_1)-smooth functions
proposed by Zhang et al. (ICLR’20). Empirical evidence suggests that these functions more closely captures practical machine learning problems as compared to the pervasive L_0-smoothness. This class is rich enough to include highly non-smooth functions, such as \exp(L_1 x) which is (0,O(L_1))-smooth. Despite the richness,  an emerging line of works achieves the O(\nicefrac1\sqrtT) rate of convergence when the noise of the stochastic gradients is deterministically and uniformly bounded. This noise restriction is not required in the L_0-smooth setting, and in many practical settings is either not satisfied, or results in weaker convergence rates with respect to the noise scaling of the convergence rate.

We develop a technique that allows us to prove O(\nicefrac\mathrmpoly\log(T)\sqrtT) convergence rates for (L_0,L_1)-smooth functions without assuming uniform bounds on the noise support. The key innovation behind our results is a carefully constructed stopping time τwhich is simultaneously “large” on average, yet also allows us to treat the adaptive step sizes before τas (roughly) independent of the gradients. For general (L_0,L_1)-smooth functions, our analysis requires the mild restriction that the multiplicative noise parameter \sigma_1 &lt; 1. For a broad subclass of (L_0,L_1)-smooth functions, our convergence rate continues to hold when \sigma_1 ≥1. By contrast, we prove that many algorithms analyzed by prior works on (L_0,L_1)-smooth optimization diverge with constant probability even for smooth and strongly-convex functions when \sigma_1 &gt; 1.</pre>
</div>


<script>
function toggleAbstractCCfaw23beyond(parameter) {
    var x= document.getElementById('afaw23beyond');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleBibtexfaw23beyond(parameter) {
    var x= document.getElementById('Bfaw23beyond');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleAbstractfaw23beyond(parameter) {
    var x= document.getElementById('afaw23beyond');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>
</li>
<li><div class="text-justify"><span id="kwon2023reward">Kwon, Jeongyeol, Yonathan Efroni, Constantine Caramanis, and Shie Mannor. “Reward-Mixing MDPs with Few Latent Contexts Are Learnable.” In <i>International Conference on Machine Learning (ICML)</i>, 18057–82. PMLR, 2023.</span></div>
<button class="button0" onclick="toggleBibtexkwon2023reward()">Bibtex</button>
 

<button class="button0" onclick="toggleAbstractkwon2023reward()">Abstract</button>



    <a href="https://arxiv.org/pdf/2210.02594.pdf"><input class="button4" type="button" value="ArXiv" /></a>

 


<div id="Bkwon2023reward" style="display: none;">
<pre>@inproceedings{kwon2023reward,
  title = {Reward-Mixing MDPs with Few Latent Contexts are Learnable},
  author = {Kwon, Jeongyeol and Efroni, Yonathan and Caramanis, Constantine and Mannor, Shie},
  booktitle = {International Conference on Machine Learning (ICML)},
  pages = {18057--18082},
  year = {2023},
  organization = {PMLR},
  group = {proceedings},
  arxiv = {https://arxiv.org/pdf/2210.02594.pdf}
}
</pre>
</div>

<div id="akwon2023reward" style="display: none;">
<pre>We consider episodic reinforcement learning in reward-mixing Markov decision processes (RMMDPs): at the beginning of every episode nature randomly picks a latent reward model among M candidates and an agent interacts with the MDP throughout the episode for H time steps. Our goal is to learn a near-optimal policy that nearly maximizes the H time-step cumulative rewards in such a model. Prior work (Kwon et al., ’21) established an upper bound for RMMDPs with M=2. In this work, we resolve several open questions for the general RMMDP setting. We consider an arbitrary M\ge2 and provide a sample-efficient algorithm that outputs an ε-optimal policy using O \left(ε^-2 ⋅S^d A^d ⋅\poly(H, Z)^d \right) episodes, where S, A are the number of states and actions respectively, H is the time-horizon, Z is the support size of reward distributions and d=O(\min(M,H)). We also provide a (SA)^Ω(\sqrtM) / ε^2 lower bound, supporting that super-polynomial sample complexity in M is necessary. </pre>
</div>


<script>
function toggleAbstractCCkwon2023reward(parameter) {
    var x= document.getElementById('akwon2023reward');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleBibtexkwon2023reward(parameter) {
    var x= document.getElementById('Bkwon2023reward');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleAbstractkwon2023reward(parameter) {
    var x= document.getElementById('akwon2023reward');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>
</li>
<li><div class="text-justify"><span id="faw2022power">Faw, Matthew, Isidoros Tziotis, Constantine Caramanis, Aryan Mokhtari, Sanjay Shakkottai, and Rachel Ward. “The Power of Adaptivity in SGD: Self-Tuning Step Sizes with Unbounded Gradients and Affine Variance.” <i>The Conference on Learning Theory (COLT)</i>, 2022.</span></div>
<button class="button0" onclick="toggleBibtexfaw2022power()">Bibtex</button>
 

<button class="button0" onclick="toggleAbstractfaw2022power()">Abstract</button>



    <a href="https://arxiv.org/pdf/2202.05791"><input class="button4" type="button" value="ArXiv" /></a>

 


<div id="Bfaw2022power" style="display: none;">
<pre>@article{faw2022power,
  title = {The Power of Adaptivity in SGD: Self-Tuning Step Sizes with Unbounded Gradients and Affine Variance},
  author = {Faw, Matthew and Tziotis, Isidoros and Caramanis, Constantine and Mokhtari, Aryan and Shakkottai, Sanjay and Ward, Rachel},
  journal = {The Conference on Learning Theory (COLT)},
  year = {2022},
  group = {proceedings},
  arxiv = {https://arxiv.org/pdf/2202.05791}
}
</pre>
</div>

<div id="afaw2022power" style="display: none;">
<pre>We study convergence rates of AdaGrad-Norm as an exemplar of adaptive stochastic gradient methods (SGD), where the step sizes change based on observed stochastic gradients, for minimizing non-convex, smooth objectives. Despite their popularity, the analysis of adaptive SGD lags behind that of non adaptive methods in this setting. Specifically, all prior works rely on some subset of the following assumptions: (i) uniformly-bounded gradient norms, (ii) uniformly-bounded stochastic gradient variance (or even noise support), (iii) conditional independence between the step size and stochastic gradient. In this work, we show that AdaGrad-Norm exhibits an order optimal convergence rate of O(polylog(T)/\sqrtT)  after T iterations under the same assumptions as optimally-tuned non adaptive SGD (unbounded gradient norms and affine noise variance scaling), and crucially, without needing any tuning parameters. We thus establish that adaptive gradient methods exhibit order-optimal convergence in much broader regimes than previously understood.</pre>
</div>


<script>
function toggleAbstractCCfaw2022power(parameter) {
    var x= document.getElementById('afaw2022power');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleBibtexfaw2022power(parameter) {
    var x= document.getElementById('Bfaw2022power');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleAbstractfaw2022power(parameter) {
    var x= document.getElementById('afaw2022power');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>
</li>
<li><div class="text-justify"><span id="kwon2022coordinated">Kwon, Jeongyeol, Yonathan Efroni, Constantine Caramanis, and Shie Mannor. “Coordinated Attacks against Contextual Bandits: Fundamental Limits and Defense Mechanisms.” <i>International Conference on Machine Learning (ICML)</i>, 2022.</span></div>
<button class="button0" onclick="toggleBibtexkwon2022coordinated()">Bibtex</button>
 

<button class="button0" onclick="toggleAbstractkwon2022coordinated()">Abstract</button>



    <a href="https://arxiv.org/pdf/2201.12700.pdf"><input class="button4" type="button" value="ArXiv" /></a>

 


<div id="Bkwon2022coordinated" style="display: none;">
<pre>@article{kwon2022coordinated,
  title = {Coordinated Attacks against Contextual Bandits: Fundamental Limits and Defense Mechanisms},
  author = {Kwon, Jeongyeol and Efroni, Yonathan and Caramanis, Constantine and Mannor, Shie},
  journal = {International Conference on Machine Learning (ICML)},
  year = {2022},
  group = {proceedings},
  arxiv = {https://arxiv.org/pdf/2201.12700.pdf}
}
</pre>
</div>

<div id="akwon2022coordinated" style="display: none;">
<pre>Motivated by online recommendation systems, we propose the problem of finding the optimal policy in multitask contextual bandits when a small fraction alpha &lt; 1/2 of tasks (users) are arbitrary and adversarial. The remaining fraction of good users share the same instance of contextual bandits with S contexts and A actions (items). Naturally, whether a user is good or adversarial is not known in advance. The goal is to robustly learn the policy that maximizes rewards for good users with as few user interactions as possible. Without adversarial users, established results in collaborative filtering show that O(1/epsilon^2) per-user interactions suffice to learn a good policy, precisely because information can be shared across users. This parallelization gain is fundamentally altered by the presence of adversarial users: unless there are super-polynomial number of users, we show a lower bound of Omega(min(S,A)alpha^2/epsilon^2) \it per-user interactions to learn an epsilon-optimal policy for the good users. We then show we can achieve an O (min(S,A) alpha /epsilon^2) upper-bound, by employing efficient robust mean estimators for both uni-variate and high-dimensional random variables. We also show that this can be improved depending on the distributions of contexts.</pre>
</div>


<script>
function toggleAbstractCCkwon2022coordinated(parameter) {
    var x= document.getElementById('akwon2022coordinated');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleBibtexkwon2022coordinated(parameter) {
    var x= document.getElementById('Bkwon2022coordinated');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleAbstractkwon2022coordinated(parameter) {
    var x= document.getElementById('akwon2022coordinated');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>
</li>
<li><div class="text-justify"><span id="atsidakou202asymptotically">Atsidakou, Alexia, Orestis Papadigenopoulos, Constantine Caramanis, Sujay Sanghavi, and Sanjay Shakkottai. “Asymptotically-Optimal Gaussian Bandits with Side Observations.” In <i>International Conference on Machine Learning (ICML)</i>. PMLR, 2022.</span></div>
<button class="button0" onclick="toggleBibtexatsidakou202asymptotically()">Bibtex</button>
 

<button class="button0" onclick="toggleAbstractatsidakou202asymptotically()">Abstract</button>



    <a href="https://proceedings.mlr.press/v162/atsidakou22a/atsidakou22a.pdf"><input class="button4" type="button" value="ArXiv" /></a>

 


<div id="Batsidakou202asymptotically" style="display: none;">
<pre>@inproceedings{atsidakou202asymptotically,
  title = {Asymptotically-Optimal Gaussian Bandits with Side Observations},
  author = {Atsidakou, Alexia and Papadigenopoulos, Orestis and Caramanis, Constantine and Sanghavi, Sujay and Shakkottai, Sanjay},
  journal = {International Conference on Machine Learning (ICML)},
  year = {2022},
  organization = {PMLR},
  group = {proceedings},
  arxiv = {https://proceedings.mlr.press/v162/atsidakou22a/atsidakou22a.pdf}
}
</pre>
</div>

<div id="aatsidakou202asymptotically" style="display: none;">
<pre>Recent work has considered natural variations of the \em multi-armed bandit problem, where the reward distribution of each arm is a special function of the time passed since its last pulling. In this direction, a simple (yet widely applicable) model is that of \em blocking bandits, where an arm becomes unavailable for a deterministic number of rounds after each play. In this work, we extend the above model in two directions: (i) We consider the general combinatorial setting where more than one arms can be played at each round, subject to feasibility constraints. (ii) We allow the blocking time of each arm to be stochastic. We first study the computational/unconditional hardness of the above setting and identify the necessary conditions for the problem to become tractable (even in an approximate sense). Based on these conditions, we provide a tight analysis of the approximation guarantee of a natural greedy heuristic that always plays the maximum expected reward feasible subset among the available (non-blocked) arms. When the arms’ expected rewards are unknown, we adapt the above heuristic into a bandit algorithm, based on UCB, for which we provide sublinear (approximate) regret guarantees, matching the theoretical lower bounds in the limiting case of absence of delays.</pre>
</div>


<script>
function toggleAbstractCCatsidakou202asymptotically(parameter) {
    var x= document.getElementById('aatsidakou202asymptotically');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleBibtexatsidakou202asymptotically(parameter) {
    var x= document.getElementById('Batsidakou202asymptotically');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleAbstractatsidakou202asymptotically(parameter) {
    var x= document.getElementById('aatsidakou202asymptotically');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>
</li>
<li><div class="text-justify"><span id="kwon2022tractable">Kwon, Jeongyeol, Yonathan Efroni, Constantine Caramanis, and Shie Mannor. “Tractable Optimality in Episodic Latent MABs.” <i>Advances in Neural Information Processing Systems (NeurIPS)</i>, 2022.</span></div>
<button class="button0" onclick="toggleBibtexkwon2022tractable()">Bibtex</button>
 

<button class="button0" onclick="toggleAbstractkwon2022tractable()">Abstract</button>



    <a href="https://arxiv.org/pdf/2210.03528.pdf"><input class="button4" type="button" value="ArXiv" /></a>

 


<div id="Bkwon2022tractable" style="display: none;">
<pre>@article{kwon2022tractable,
  title = {Tractable Optimality in Episodic Latent MABs},
  author = {Kwon, Jeongyeol and Efroni, Yonathan and Caramanis, Constantine and Mannor, Shie},
  journal = {Advances in Neural Information Processing Systems (NeurIPS)},
  year = {2022},
  group = {proceedings},
  arxiv = {https://arxiv.org/pdf/2210.03528.pdf}
}
</pre>
</div>

<div id="akwon2022tractable" style="display: none;">
<pre>We consider a multi-armed bandit problem with A actions and M latent contexts, where an agent interacts with the environment for an episode of H time steps. Depending on the length of the episode, the learner may not be able to estimate accurately the latent context. The resulting partial observation of the environment makes the learning task significantly more challenging. 
Without any additional structural assumptions, existing techniques to tackle partially observed settings imply the decision maker can learn a near-optimal policy with O(A)^H episodes, but do not promise more. 
In this work, we show that learning with \em polynomial samples in A is possible. We achieve this by using techniques from experiment design. Then, through a method-of-moments approach, we design a procedure that provably learns a near-optimal policy with O(\poly(A) + \poly(M,H)^\min(M,H)) interactions. In practice, we show that we can formulate the moment-matching via maximum likelihood estimation. In our experiments, this significantly outperforms the worst-case guarantees, as well as existing practical methods.</pre>
</div>


<script>
function toggleAbstractCCkwon2022tractable(parameter) {
    var x= document.getElementById('akwon2022tractable');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleBibtexkwon2022tractable(parameter) {
    var x= document.getElementById('Bkwon2022tractable');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleAbstractkwon2022tractable(parameter) {
    var x= document.getElementById('akwon2022tractable');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>
</li>
<li><div class="text-justify"><span id="papadigenopoulos2022non">Papadigenopoulos, Orestis, Constantine Caramanis, and Sanjay Shakkottai. “Non-Stationary Bandits under Recharging Payoffs: Improved Planning with Sublinear Regret.” In <i>Advances in Neural Information Processing Systems (NeurIPS)</i>, 2022.</span></div>
<button class="button0" onclick="toggleBibtexpapadigenopoulos2022non()">Bibtex</button>
 

<button class="button0" onclick="toggleAbstractpapadigenopoulos2022non()">Abstract</button>



    <a href="https://arxiv.org/pdf/2205.14790.pdf"><input class="button4" type="button" value="ArXiv" /></a>

 


<div id="Bpapadigenopoulos2022non" style="display: none;">
<pre>@inproceedings{papadigenopoulos2022non,
  title = {Non-Stationary Bandits under Recharging Payoffs: Improved Planning with Sublinear Regret},
  author = {Papadigenopoulos, Orestis and Caramanis, Constantine and Shakkottai, Sanjay},
  journal = {Advances in Neural Information Processing Systems (NeurIPS)},
  year = {2022},
  group = {proceedings},
  arxiv = {https://arxiv.org/pdf/2205.14790.pdf}
}
</pre>
</div>

<div id="apapadigenopoulos2022non" style="display: none;">
<pre>The stochastic multi-armed bandit setting has been recently studied in the non-stationary regime, where the mean payoff of each action is a non-decreasing function of the number of rounds passed since it was last played. This model captures natural behavioral aspects of the users which crucially determine the performance of recommendation platforms, ad placement systems, and more. Even assuming prior knowledge of the mean payoff functions, computing an optimal planning in the above model is NP-hard, while the state-of-the-art is a 1/4-approximation algorithm for the case where at most one arm can be played per round. We first focus on the setting where the mean payoff functions are known. In this setting, we significantly improve the best-known guarantees for the planning problem by developing a polynomial-time (1?1/e)-approximation algorithm (asymptotically and in expectation), based on a novel combination of randomized LP rounding and a time-correlated (interleaved) scheduling method. Furthermore, our algorithm achieves improved guarantees – compared to prior work – for the case where more than one arm can be played at each round. Moving to the bandit setting, when the mean payoff functions are initially unknown, we show how our algorithm can be transformed into a bandit algorithm with sublinear regret.</pre>
</div>


<script>
function toggleAbstractCCpapadigenopoulos2022non(parameter) {
    var x= document.getElementById('apapadigenopoulos2022non');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleBibtexpapadigenopoulos2022non(parameter) {
    var x= document.getElementById('Bpapadigenopoulos2022non');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleAbstractpapadigenopoulos2022non(parameter) {
    var x= document.getElementById('apapadigenopoulos2022non');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>
</li>
<li><div class="text-justify"><span id="katiyarRobustMRF2021">Katiyar, Ashish, Soumya Basu, Vatsal Shah, and Constantine Caramanis. “Robust Estimation of Tree Structured Markov Random Fields.” <i>International Conference on Artificial Intelligence and Statistics (AISTATS)</i>, 2022.</span></div>
<button class="button0" onclick="toggleBibtexkatiyarRobustMRF2021()">Bibtex</button>
 

<button class="button0" onclick="toggleAbstractkatiyarRobustMRF2021()">Abstract</button>



    <a href="https://arxiv.org/pdf/2102.08554.pdf"><input class="button4" type="button" value="ArXiv" /></a>

 


<div id="BkatiyarRobustMRF2021" style="display: none;">
<pre>@article{katiyarRobustMRF2021,
  title = {Robust Estimation of Tree Structured Markov Random Fields},
  author = {Katiyar, Ashish and Basu, Soumya and Shah, Vatsal and Caramanis, Constantine},
  booktitle = {International Conference on Artificial Intelligence and Statistics (AISTATS)},
  year = {2022},
  group = {proceedings},
  arxiv = {https://arxiv.org/pdf/2102.08554.pdf}
}
</pre>
</div>

<div id="akatiyarRobustMRF2021" style="display: none;">
<pre>We study the problem of learning tree-structured Markov random fields (MRF) on discrete random variables with common support when the observations are corrupted by a k-ary symmetric noise channel with unknown probability of error. 
 For Ising models (support size = 2), past work has shown that graph structure can only be recovered up to the leaf clusters (a leaf node, its parent, and its siblings form a leaf cluster) and exact recovery is impossible. No prior work has addressed the setting of support size of 3 or more, and indeed this setting is far richer. As we show, when the support size is 3 or more, the structure of the leaf clusters may be partially or fully identifiable. We provide a precise characterization of this phenomenon and show that the extent of recoverability is dictated by the joint PMF of the random variables.  In particular, we provide necessary and sufficient conditions for exact recoverability. Furthermore, we present a polynomial time, sample efficient algorithm that recovers the exact tree when this is possible, or up to the unidentifiability as promised by our characterization, when full recoverability is impossible. Finally, we  demonstrate the efficacy of our algorithm experimentally.</pre>
</div>


<script>
function toggleAbstractCCkatiyarRobustMRF2021(parameter) {
    var x= document.getElementById('akatiyarRobustMRF2021');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleBibtexkatiyarRobustMRF2021(parameter) {
    var x= document.getElementById('BkatiyarRobustMRF2021');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<script>
function toggleAbstractkatiyarRobustMRF2021(parameter) {
    var x= document.getElementById('akatiyarRobustMRF2021');
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>
</li></ol>


</div>

    </div>
    
  </body>
</html>
